{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahdrakes/mldl-final/blob/main/mm_violence_det_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDOr6KirJvUe"
      },
      "source": [
        "# Multi-Modal Violence Detection Network\n",
        "\n",
        "original src code: https://github.com/Roc-Ng/XDVioDet.git\n",
        "\n",
        "Data can be downloaded here: https://roc-ng.github.io/XD-Violence/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhzPvDXTKKqM"
      },
      "source": [
        "### Copying Training and Testing Data\n",
        "\n",
        "The folders are pretty large (~40/50GB) so it takes a while to copy all of the data over.\n",
        "\n",
        "Data can be downloaded here: https://roc-ng.github.io/XD-Violence/ under V1.0 Features. Then upload the data to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4DG4K3wYK8P",
        "outputId": "e3d8bef1-7e0f-497e-b7c3-690c28baffed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /mydrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/mydrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88GWL7hscvcg",
        "outputId": "c239aeed-6d09-4c08-dd5d-f103fd088298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/mydrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /mydrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Nr7SpsS-2P6x"
      },
      "outputs": [],
      "source": [
        "!unzip final_dl.zip -d /content/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zWKH9vsRatb"
      },
      "source": [
        "may need to change directory depending on where you upload the data to google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CHQ29LtvAsNj"
      },
      "outputs": [],
      "source": [
        "# !cp -r /mydrive/MyDrive/final_dl ./"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Flight\n",
        "\n",
        "Some utils, classes, helpers, data splitters to run before selecting a workflow"
      ],
      "metadata": {
        "id": "WEsLZHVzkiMq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLV269m9K7L3"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ej2MARCmKzvk"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def random_extract(feat, t_max):\n",
        "   r = np.random.randint(len(feat)-t_max)\n",
        "   return feat[r:r+t_max]\n",
        "\n",
        "def uniform_extract(feat, t_max):\n",
        "   r = np.linspace(0, len(feat)-1, t_max, dtype=np.uint16)\n",
        "   return feat[r, :]\n",
        "\n",
        "def pad(feat, min_len):\n",
        "    if np.shape(feat)[0] <= min_len:\n",
        "       return np.pad(feat, ((0, min_len-np.shape(feat)[0]), (0, 0)), mode='constant', constant_values=0)\n",
        "    else:\n",
        "       return feat\n",
        "\n",
        "def process_feat(feat, length, is_random=True):\n",
        "    if len(feat) > length:\n",
        "        if is_random:\n",
        "            return random_extract(feat, length)\n",
        "        else:\n",
        "            return uniform_extract(feat, length)\n",
        "    else:\n",
        "        return pad(feat, length)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z-JVZlBNeg4"
      },
      "source": [
        "## Args\n",
        "\n",
        "Here are the default args that were obtained via cmd line arg parser. I just created a class 'Args' that holds the default config for the model.\n",
        "\n",
        "I think the most important args:\n",
        "\n",
        "*`Modality`*: Determines whether we want to use either audio alone, video alone, both audio and video, audio, video, and flow, etc. for training\n",
        "\n",
        "*`List`*: point to the list containing filenames for all training and testing data.\n",
        "\n",
        "*`workers`*: I believe this is the number of individual threads/processes running during training or testing. In ther model it was set to 4 by defualt but that spit out an error so it lowered it to 1. Prob a sign that we need to do heavy downsampling to compensate for lack of parallel processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0g_4ciyOM8tl"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.modality = 'MIX2'\n",
        "        # Original paths\n",
        "        self.rgb_list = '/content/final_dl/list/rgb.list'\n",
        "        self.flow_list = '/content/final_dl/list/flow.list'\n",
        "        self.audio_list = '/content/final_dl/list/audio.list'\n",
        "\n",
        "        # Train paths\n",
        "        self.train_rgb_list = '/content/final_dl/list/rgb_train.list'\n",
        "        self.train_flow_list = '/content/final_dl/list/flow_train.list'\n",
        "        self.train_audio_list = '/content/final_dl/list/audio_train.list'\n",
        "\n",
        "        # Val paths\n",
        "        self.val_rgb_list = '/content/final_dl/list/rgb_val.list'\n",
        "        self.val_flow_list = '/content/final_dl/list/flow_val.list'\n",
        "        self.val_audio_list = '/content/final_dl/list/audio_val.list'\n",
        "\n",
        "        # Test paths\n",
        "        self.test_rgb_list = '/content/final_dl/list/rgb_test.list'\n",
        "        self.test_flow_list = '/content/final_dl/list/flow_test.list'\n",
        "        self.test_audio_list = '/content/final_dl/list/audio_test.list'\n",
        "\n",
        "        self.gt = '/content/final_dl/list/gt.npy'\n",
        "        self.gpus = 1\n",
        "        self.lr = 0.0001\n",
        "        self.batch_size = 128\n",
        "        self.workers = 1  # Reduced from 4 to avoid memory issues\n",
        "        self.model_name = 'wsanodet'\n",
        "        self.pretrained_ckpt = None\n",
        "        self.feature_size = 1152  # 1024 + 128\n",
        "        self.num_classes = 1\n",
        "        self.dataset_name = 'XD-Violence'\n",
        "        self.max_seqlen = 200\n",
        "        self.max_epoch = 50\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "class for building a dataset"
      ],
      "metadata": {
        "id": "SLX1ouIEy6o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, args, transform=None, mode='train'):\n",
        "        self.modality = args.modality\n",
        "        self.max_seqlen = args.max_seqlen\n",
        "        self.transform = transform\n",
        "        self.test_mode = (mode == 'test')\n",
        "\n",
        "        # Set appropriate file lists based on mode\n",
        "        if mode == 'test':\n",
        "            self.rgb_list_file = args.test_rgb_list\n",
        "            self.flow_list_file = args.test_flow_list\n",
        "            self.audio_list_file = args.test_audio_list\n",
        "        elif mode == 'val':\n",
        "            self.rgb_list_file = args.val_rgb_list\n",
        "            self.flow_list_file = args.val_flow_list\n",
        "            self.audio_list_file = args.val_audio_list\n",
        "        else:  # train\n",
        "            self.rgb_list_file = args.train_rgb_list\n",
        "            self.flow_list_file = args.train_flow_list\n",
        "            self.audio_list_file = args.train_audio_list\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _parse_list(self):\n",
        "        \"\"\"Parse file lists - assumes lists are already properly aligned\"\"\"\n",
        "        if self.modality == 'MIX2':\n",
        "            self.list = [line.strip() for line in open(self.rgb_list_file)]\n",
        "            self.audio_list = [line.strip() for line in open(self.audio_list_file)]\n",
        "        elif self.modality == 'AUDIO':\n",
        "            self.list = [line.strip() for line in open(self.audio_list_file)]\n",
        "        elif self.modality == 'RGB':\n",
        "            self.list = [line.strip() for line in open(self.rgb_list_file)]\n",
        "        elif self.modality == 'FLOW':\n",
        "            self.list = [line.strip() for line in open(self.flow_list_file)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.modality in ['RGB', 'FLOW', 'AUDIO']:\n",
        "            file_path = self.list[index].strip()\n",
        "            features = np.array(np.load(file_path), dtype=np.float32)\n",
        "            label = 0.0 if '_label_A' in file_path else 1.0\n",
        "        elif self.modality == 'MIX2':\n",
        "            # Load RGB features\n",
        "            file_path1 = self.list[index].strip()\n",
        "            features1 = np.array(np.load(file_path1), dtype=np.float32)\n",
        "            label = 0.0 if '_label_A' in file_path1 else 1.0\n",
        "\n",
        "            # Load corresponding audio features\n",
        "            audio_index = index // 5\n",
        "            file_path2 = self.audio_list[audio_index].strip()\n",
        "            features2 = np.array(np.load(file_path2), dtype=np.float32)\n",
        "\n",
        "            features = np.concatenate((features1, features2), axis=1)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        features = process_feat(features, self.max_seqlen, is_random=not self.test_mode)\n",
        "        return features, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list)\n"
      ],
      "metadata": {
        "id": "ifPggCa2y-fB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting (Test, Train, Val)\n",
        "\n",
        "paths are hard-coded and can be adjusted as needed"
      ],
      "metadata": {
        "id": "GUjftlqFkqx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "def get_video_id(filepath):\n",
        "    \"\"\"Extract consistent video ID for both RGB and audio files\"\"\"\n",
        "    filename = os.path.basename(filepath)\n",
        "\n",
        "    # Handle RGB files (end with __[0-4].npy)\n",
        "    if filename.endswith(('.npy')):\n",
        "        base = filename.rsplit('__', 1)[0]  # Split from the right on __ to remove the number or vggish\n",
        "        return base\n",
        "\n",
        "    # Fallback - just remove extension\n",
        "    return filename.split('.')[0]\n",
        "\n",
        "def create_splits(aligned_files, train_ratio=0.8, seed=42):\n",
        "    \"\"\"Split the video IDs first, then we'll expand to files in write_list_files\"\"\"\n",
        "    random.seed(seed)\n",
        "    video_ids = list(aligned_files.keys())\n",
        "    train_size = int(len(video_ids) * train_ratio)\n",
        "    train_ids = random.sample(video_ids, train_size)\n",
        "    val_ids = [vid for vid in video_ids if vid not in train_ids]\n",
        "    return {\n",
        "        'train': train_ids,\n",
        "        'val': val_ids\n",
        "    }\n",
        "def write_list_files(split_data, aligned_files, outputdir=\"/content/final_dl/list\"):\n",
        "    \"\"\"Write list files with audio files repeated to match RGB structure\"\"\"\n",
        "    #os.makedirs(outputdir, exist_ok=True)\n",
        "    for split_name, video_ids in split_data.items():\n",
        "        # RGB list - one entry per frame\n",
        "        rgb_path = os.path.join(outputdir, f'rgb_{split_name}.list')\n",
        "        with open(rgb_path, 'w') as f:\n",
        "            for vid_id in video_ids:\n",
        "                for rgb_file in aligned_files[vid_id]['rgb']:\n",
        "                    f.write(f\"{rgb_file}\\n\")\n",
        "        # Audio list - one entry per video (not per frame)\n",
        "        audio_path = os.path.join(outputdir, f'audio_{split_name}.list')\n",
        "        with open(audio_path, 'w') as f:\n",
        "            for vid_id in video_ids:\n",
        "                audio_file = aligned_files[vid_id]['audio']\n",
        "                f.write(f\"{audio_file}\\n\")\n",
        "\n",
        "def find_matching_files():\n",
        "    \"\"\"\n",
        "    Find and align RGB and audio feature files.\n",
        "    Only includes files that actually exist in the filesystem.\n",
        "    Returns dict mapping video IDs to their RGB and audio paths\n",
        "    \"\"\"\n",
        "    rgb_path = \"/content/final_dl/dl_files/i3d-features/RGB\"\n",
        "    audio_path = \"/content/final_dl/list/xx/train\"\n",
        "\n",
        "    # Get all files\n",
        "    rgb_files = [f for f in glob.glob(os.path.join(rgb_path, \"*.npy\")) if os.path.exists(f)]\n",
        "    audio_files = [f for f in glob.glob(os.path.join(audio_path, \"*.npy\")) if os.path.exists(f)]\n",
        "\n",
        "    # Create mappings that preserve the 5:1 ratio\n",
        "    rgb_map = {}\n",
        "    for f in rgb_files:\n",
        "        vid_id = get_video_id(f)\n",
        "        if vid_id not in rgb_map:\n",
        "            rgb_map[vid_id] = []\n",
        "        rgb_map[vid_id].append(f)\n",
        "    audio_map = {}\n",
        "    for f in audio_files:\n",
        "        if os.path.exists(f):\n",
        "            vid_id = get_video_id(f)\n",
        "            audio_map[vid_id] = f\n",
        "\n",
        "    # Find common video IDs and verify each RGB group has exactly 5 files\n",
        "    common_ids = set(rgb_map.keys()) & set(audio_map.keys())\n",
        "    complete_ids = {vid_id for vid_id in common_ids if len(rgb_map[vid_id]) == 5}\n",
        "\n",
        "    # Create aligned mapping only for complete groups\n",
        "    aligned_files = {\n",
        "        vid_id: {\n",
        "            'rgb': sorted(rgb_map[vid_id]),  # Sort to maintain consistent ordering\n",
        "            'audio': audio_map[vid_id],\n",
        "            'is_normal': '_label_A' in rgb_map[vid_id][0]  # Check first RGB file for label\n",
        "        }\n",
        "        for vid_id in complete_ids\n",
        "    }\n",
        "\n",
        "    return aligned_files"
      ],
      "metadata": {
        "id": "NRVNY_NEcEB5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this:\n",
        "aligned_files = find_matching_files()\n",
        "\n",
        "# Create train/val splits\n",
        "split_data = create_splits(aligned_files)\n",
        "\n",
        "# Write list files\n",
        "write_list_files(split_data, aligned_files)"
      ],
      "metadata": {
        "id": "llIpmyVVlFIj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix Test Files\n",
        "\n",
        "There are already {mode}_test.list files in the list dir. We need to update these paths because they are hardcoded to a destination on the original authors' machine. Run these next few lines just once:"
      ],
      "metadata": {
        "id": "Poik5qqplNKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/final_dl/list\n",
        "# Uncommnet these and run ONLY ONCE\n",
        "#!sed -i 's|/media/peng/Samsung_T5|/content/final_dl/dl_files|g' rgb_test.list\n",
        "#!sed -i 's|/media/peng/Samsung_T5/vggish-features|/content/final_dl/list/xx|g' audio_test.list\n",
        "# Verify paths\n",
        "!head -n 5 /content/final_dl/list/rgb_test.list\n",
        "!head -n 5 /content/final_dl/list/audio_test.list\n",
        "%cd /mydrive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlgT5wbQl4Jm",
        "outputId": "ae19c56a-be55-4d74-c9da-55ca6f1a1259"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/final_dl/list\n",
            "/content/final_dl/dl_files/i3d-features/RGBTest/Bad.Boys.1995__#01-11-55_01-12-40_label_G-B2-B6__0.npy\n",
            "/content/final_dl/dl_files/i3d-features/RGBTest/Bad.Boys.1995__#01-11-55_01-12-40_label_G-B2-B6__1.npy\n",
            "/content/final_dl/dl_files/i3d-features/RGBTest/Bad.Boys.1995__#01-11-55_01-12-40_label_G-B2-B6__2.npy\n",
            "/content/final_dl/dl_files/i3d-features/RGBTest/Bad.Boys.1995__#01-11-55_01-12-40_label_G-B2-B6__3.npy\n",
            "/content/final_dl/dl_files/i3d-features/RGBTest/Bad.Boys.1995__#01-11-55_01-12-40_label_G-B2-B6__4.npy\n",
            "/content/final_dl/list/xx/test/Bad.Boys.1995__#01-11-55_01-12-40_label_G-B2-B6__vggish.npy\n",
            "/content/final_dl/list/xx/test/Bad.Boys.1995__#01-33-51_01-34-37_label_B2-0-0__vggish.npy\n",
            "/content/final_dl/list/xx/test/Bad.Boys.II.2003__#00-06-42_00-10-00_label_B2-G-0__vggish.npy\n",
            "/content/final_dl/list/xx/test/Black.Hawk.Down.2001__#01-13-59_01-14-49_label_B2-0-0__vggish.npy\n",
            "/content/final_dl/list/xx/test/Black.Hawk.Down.2001__#01-32-40_01-34-00_label_B4-0-0__vggish.npy\n",
            "/mydrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataloaders for multimodal"
      ],
      "metadata": {
        "id": "gJzaD9WsT3YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "def create_data_loaders(args):\n",
        "    \"\"\"\n",
        "    Create train, validation and test data loaders\n",
        "    \"\"\"\n",
        "    print(\"Creating data loaders...\")\n",
        "\n",
        "    # Create train loader\n",
        "    train_dataset = Dataset(args, mode='train')\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Train loader created with {len(train_dataset)} samples\")\n",
        "\n",
        "    # Create validation loader\n",
        "    val_dataset = Dataset(args, mode='val')\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,  # No need to shuffle validation data\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Validation loader created with {len(val_dataset)} samples\")\n",
        "\n",
        "    # Create test loader with smaller batch size as per original code\n",
        "    test_dataset = Dataset(args, mode='test')\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=5,  # Using smaller batch size for testing\n",
        "        shuffle=False,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "args = Args()\n",
        "train_loader, val_loader, test_loader = create_data_loaders(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVCYAPTSTuQY",
        "outputId": "a75920c0-f9c3-4532-af89-686bb72d5e89"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating data loaders...\n",
            "Train loader created with 15815 samples\n",
            "Validation loader created with 3955 samples\n",
            "Test loader created with 4000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAL SPLIT FOR SINGLE MODALITY"
      ],
      "metadata": {
        "id": "CsN1t5SrTQoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_single_modality_data_loaders(args, modality='AUDIO'):\n",
        "    \"\"\"\n",
        "    Create train, validation and test data loaders for a single modality\n",
        "    \"\"\"\n",
        "    print(f\"Creating {modality} data loaders...\")\n",
        "\n",
        "    # Create new args with only needed attributes\n",
        "    args_new = Args()\n",
        "    args_new.modality = modality\n",
        "\n",
        "    # List files needed for train/val/test splits\n",
        "    if modality == 'AUDIO':\n",
        "        args_new.train_audio_list = args.train_audio_list\n",
        "        args_new.val_audio_list = args.val_audio_list\n",
        "        args_new.test_audio_list = args.test_audio_list\n",
        "    elif modality == 'RGB':\n",
        "        args_new.train_rgb_list = args.train_rgb_list\n",
        "        args_new.val_rgb_list = args.val_rgb_list\n",
        "        args_new.test_rgb_list = args.test_rgb_list\n",
        "    elif modality == 'FLOW':\n",
        "        args_new.train_flow_list = args.train_flow_list\n",
        "        args_new.val_flow_list = args.val_flow_list\n",
        "        args_new.test_flow_list = args.test_flow_list\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = Dataset(args_new, mode='train')\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args_new.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args_new.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Train loader created with {len(train_dataset)} samples\")\n",
        "\n",
        "    val_dataset = Dataset(args_new, mode='val')\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args_new.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args_new.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Validation loader created with {len(val_dataset)} samples\")\n",
        "\n",
        "    test_dataset = Dataset(args_new, mode='test')\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=5,\n",
        "        shuffle=False,\n",
        "        num_workers=args_new.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "Y7aaqgH5TP66"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For audio only\n",
        "#train_loader, val_loader, test_loader = create_single_modality_data_loaders(args, modality='AUDIO')\n",
        "\n",
        "# For RGB only\n",
        "#train_loader, val_loader, test_loader = create_single_modality_data_loaders(args, modality='RGB')\n",
        "\n",
        "# For flow only\n",
        "## CURRENTLY, FLOW IS NOT SUPPORTED, BUT IMPLEMENTING IT WOULD NOT BE THAT CHALLENGING. YOU WOULD SIMPLY HAVE TO\n",
        "## ADJUST THE CODE A FEW CELLS ABOVE SO TO WRITE AN EQUIVALENT OF \"find_matching_files\" FOR FLOW DATA\n",
        "#train_loader, val_loader, test_loader = create_single_modality_data_loaders(args, modality='FLOW')"
      ],
      "metadata": {
        "id": "OtwEJzeJTr-i",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYjtaIacOHyS"
      },
      "source": [
        "# Training VAE\n",
        "Trains the multimodal VAE and single-modality VAEs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE MODEL"
      ],
      "metadata": {
        "id": "FRzWrGepsWur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class Sampling(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, z_means, z_log_vars):\n",
        "        epsilon = torch.randn_like(z_means, dtype=torch.float32)\n",
        "        return z_means + torch.exp(0.5 * z_log_vars) * epsilon\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim, input_dim=1152, seq_len=200):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Reduced number of feature maps in encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, 256, kernel_size=3, stride=2, padding=1),  # Reduced from 576\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(256, 128, kernel_size=3, stride=2, padding=1),  # Reduced from 288\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(128, 64, kernel_size=3, stride=2, padding=1),  # Reduced from 144\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        flattened_dim = 64 * 25  # Updated based on reduced features\n",
        "\n",
        "        self.lin_mean = nn.Sequential(\n",
        "            nn.Linear(flattened_dim, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim)\n",
        "        )\n",
        "\n",
        "        self.lin_log_var = nn.Sequential(\n",
        "            nn.Linear(flattened_dim, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim)\n",
        "        )\n",
        "\n",
        "        self.sampling = Sampling()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.encoder(x)\n",
        "        z_means = self.lin_mean(x)\n",
        "        z_log_vars = self.lin_log_var(x)\n",
        "        z = self.sampling(z_means, z_log_vars)\n",
        "        return z, z_means, z_log_vars\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, input_dim=1152, seq_len=200):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        flattened_dim = 64 * 25  # Updated based on reduced features\n",
        "\n",
        "        self.decoder_fc = nn.Sequential(\n",
        "            nn.Linear(latent_dim, flattened_dim),\n",
        "            nn.BatchNorm1d(flattened_dim),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # Reduced number of feature maps in decoder\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose1d(64, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # Reduced from 144->288\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose1d(128, 256, kernel_size=3, stride=2, padding=1, output_padding=1),  # Reduced from 288->576\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose1d(256, input_dim, kernel_size=3, stride=2, padding=1, output_padding=1),  # Reduced from 576->input_dim\n",
        "            nn.BatchNorm1d(input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.decoder_fc(x)\n",
        "        x = x.view(-1, 64, 25)  # Updated based on reduced features\n",
        "        x = self.decoder_conv(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim, input_dim=1152, seq_len=200):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(latent_dim, input_dim, seq_len)\n",
        "        self.decoder = Decoder(latent_dim, input_dim, seq_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z, z_means, z_log_vars = self.encoder(x)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        return x_reconstructed, z_means, z_log_vars"
      ],
      "metadata": {
        "collapsed": true,
        "id": "r7Hlyuuos9DQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reimplement Dataset Class for Normal Samples\n",
        "\n",
        "The VAE is pre-trained on only normal (non-anomalous) samples"
      ],
      "metadata": {
        "id": "nqpVoxr_uCKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "class NormalDataset(data.Dataset):\n",
        "    def __init__(self, args, transform=None, mode='train'):\n",
        "        self.modality = args.modality\n",
        "        self.normal_flag = '_label_A'\n",
        "        self.max_seqlen = args.max_seqlen\n",
        "        self.transform = transform\n",
        "        self.test_mode = (mode == 'test')\n",
        "\n",
        "        # Set appropriate file lists based on mode\n",
        "        if mode == 'test':\n",
        "            self.rgb_list_file = args.test_rgb_list\n",
        "            self.flow_list_file = args.test_flow_list\n",
        "            self.audio_list_file = args.test_audio_list\n",
        "        elif mode == 'val':\n",
        "            self.rgb_list_file = args.val_rgb_list\n",
        "            self.flow_list_file = args.val_flow_list\n",
        "            self.audio_list_file = args.val_audio_list\n",
        "        else:  # train\n",
        "            self.rgb_list_file = args.train_rgb_list\n",
        "            self.flow_list_file = args.train_flow_list\n",
        "            self.audio_list_file = args.train_audio_list\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _parse_list(self):\n",
        "        \"\"\"Parse file lists and filter for normal samples only\"\"\"\n",
        "        def filter_normal_samples(file_list):\n",
        "            return [f for f in file_list if self.normal_flag in f]\n",
        "\n",
        "        if self.modality == 'AUDIO':\n",
        "            self.list = filter_normal_samples(list(open(self.audio_list_file)))\n",
        "        elif self.modality == 'RGB':\n",
        "            self.list = filter_normal_samples(list(open(self.rgb_list_file)))\n",
        "        elif self.modality == 'FLOW':\n",
        "            self.list = filter_normal_samples(list(open(self.flow_list_file)))\n",
        "        elif self.modality == 'MIX2':\n",
        "            # For MIX2, we need to handle the 5:1 ratio between RGB and audio\n",
        "            self.list = filter_normal_samples(list(open(self.rgb_list_file)))\n",
        "            # Filter audio list and ensure alignment\n",
        "            all_audio = list(open(self.audio_list_file))\n",
        "            self.audio_list = [f for f in all_audio if self.normal_flag in f]\n",
        "\n",
        "            # Ensure RGB and audio lists are aligned (5:1 ratio)\n",
        "            rgb_video_ids = set([self._get_video_id(f) for f in self.list])\n",
        "            audio_video_ids = set([self._get_video_id(f) for f in self.audio_list])\n",
        "            common_ids = rgb_video_ids & audio_video_ids\n",
        "\n",
        "            # Filter lists to only include common videos\n",
        "            self.list = [f for f in self.list if self._get_video_id(f) in common_ids]\n",
        "            self.audio_list = [f for f in self.audio_list if self._get_video_id(f) in common_ids]\n",
        "\n",
        "    def _get_video_id(self, filepath):\n",
        "        \"\"\"Extract video ID from filepath\"\"\"\n",
        "        filename = os.path.basename(filepath.strip('\\n'))\n",
        "        return filename.split('_label')[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.modality in ['RGB', 'FLOW', 'AUDIO']:\n",
        "            features = np.array(np.load(self.list[index].strip('\\n')), dtype=np.float32)\n",
        "        elif self.modality == 'MIX2':\n",
        "            # Load RGB features\n",
        "            features1 = np.array(np.load(self.list[index].strip('\\n')), dtype=np.float32)\n",
        "            # Load corresponding audio features (accounting for 5:1 ratio)\n",
        "            audio_index = index // 5\n",
        "            features2 = np.array(np.load(self.audio_list[audio_index].strip('\\n')), dtype=np.float32)\n",
        "\n",
        "            # Handle potential dimension mismatch\n",
        "            if features1.shape[0] > features2.shape[0]:\n",
        "                features1 = features1[:features2.shape[0]]\n",
        "            features = np.concatenate((features1, features2), axis=1)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        features = process_feat(features, self.max_seqlen, is_random=not self.test_mode)\n",
        "\n",
        "        # Always return label 0 since these are normal samples\n",
        "        return features, 0.0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list)\n",
        "\n",
        "def create_normal_data_loaders(args):\n",
        "    \"\"\"Create data loaders for normal samples only\"\"\"\n",
        "    print(\"Creating normal-only data loaders...\")\n",
        "\n",
        "    # Create train loader\n",
        "    train_dataset = NormalDataset(args, mode='train')\n",
        "    train_loader = data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Normal train loader created with {len(train_dataset)} samples\")\n",
        "\n",
        "    # Create validation loader\n",
        "    val_dataset = NormalDataset(args, mode='val')\n",
        "    val_loader = data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Normal validation loader created with {len(val_dataset)} samples\")\n",
        "\n",
        "    # Create test loader\n",
        "    test_dataset = NormalDataset(args, mode='test')\n",
        "    test_loader = data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Normal test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def process_feat(feat, length, is_random=True):\n",
        "    \"\"\"Process features to have consistent length\"\"\"\n",
        "    if len(feat) > length:\n",
        "        if is_random:\n",
        "            r = np.random.randint(len(feat) - length)\n",
        "            return feat[r:r + length]\n",
        "        else:\n",
        "            r = np.linspace(0, len(feat) - 1, length, dtype=np.uint16)\n",
        "            return feat[r, :]\n",
        "    else:\n",
        "        return np.pad(feat, ((0, length - len(feat)), (0, 0)), mode='constant', constant_values=0)\n"
      ],
      "metadata": {
        "id": "T9Bi_42c8Tts"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE Pretraining\n"
      ],
      "metadata": {
        "id": "dUfjc_eorOqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return self.early_stop\n",
        "\n",
        "def validate_vae(vae, val_loader, device):\n",
        "    \"\"\"Run validation loop and return average loss\"\"\"\n",
        "    vae.eval()\n",
        "    total_loss = 0\n",
        "    total_recon_loss = 0\n",
        "    total_kl_loss = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, labels in val_loader:\n",
        "            # Only process normal samples (label == 0)\n",
        "            normal_mask = (labels == 0.0)\n",
        "            if not normal_mask.any():\n",
        "                continue\n",
        "\n",
        "            data = data[normal_mask].to(device)\n",
        "            recon_data, mu, logvar = vae(data)\n",
        "\n",
        "            # Reconstruction loss\n",
        "            recon_criterion = torch.nn.MSELoss(reduction='sum')\n",
        "            recon_loss = recon_criterion(recon_data, data)\n",
        "\n",
        "            # KL divergence loss\n",
        "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "            # Total loss\n",
        "            loss = recon_loss + kl_loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_recon_loss += recon_loss.item()\n",
        "            total_kl_loss += kl_loss.item()\n",
        "            n_samples += data.size(0)\n",
        "\n",
        "    # Calculate averages\n",
        "    if n_samples > 0:\n",
        "        avg_loss = total_loss / n_samples\n",
        "        avg_recon = total_recon_loss / n_samples\n",
        "        avg_kl = total_kl_loss / n_samples\n",
        "    else:\n",
        "        avg_loss = float('inf')\n",
        "        avg_recon = float('inf')\n",
        "        avg_kl = float('inf')\n",
        "\n",
        "    vae.train()\n",
        "    return avg_loss, avg_recon, avg_kl\n",
        "\n",
        "def train_vae(vae, train_loader, val_loader, args, save_dir='vae_checkpoints'):\n",
        "    \"\"\"Main training loop for VAE\"\"\"\n",
        "\n",
        "    # Create directory for saving checkpoints\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Setup\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    vae = vae.to(device)\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=args.lr)\n",
        "    early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_recon': [],\n",
        "        'train_kl': [],\n",
        "        'val_loss': [],\n",
        "        'val_recon': [],\n",
        "        'val_kl': []\n",
        "    }\n",
        "\n",
        "    # Training loop\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(args.max_epoch):\n",
        "        # Training\n",
        "        vae.train()\n",
        "        train_loss = 0\n",
        "        train_recon = 0\n",
        "        train_kl = 0\n",
        "        n_samples = 0\n",
        "\n",
        "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "            # Only process normal samples (label == 0)\n",
        "            normal_mask = (labels == 0.0)\n",
        "            if not normal_mask.any():\n",
        "                continue\n",
        "\n",
        "            data = data[normal_mask].to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            recon_data, mu, logvar = vae(data)\n",
        "\n",
        "            # Losses\n",
        "            recon_criterion = torch.nn.MSELoss(reduction='sum')\n",
        "            recon_loss = recon_criterion(recon_data, data)\n",
        "            kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "            loss = recon_loss + kl_loss\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Record losses\n",
        "            train_loss += loss.item()\n",
        "            train_recon += recon_loss.item()\n",
        "            train_kl += kl_loss.item()\n",
        "            n_samples += data.size(0)\n",
        "\n",
        "        # Calculate average training losses\n",
        "        if n_samples > 0:\n",
        "            avg_train_loss = train_loss / n_samples\n",
        "            avg_train_recon = train_recon / n_samples\n",
        "            avg_train_kl = train_kl / n_samples\n",
        "        else:\n",
        "            print(\"Warning: No normal samples in training batch\")\n",
        "            continue\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_recon, val_kl = validate_vae(vae, val_loader, device)\n",
        "\n",
        "        # Print progress\n",
        "        print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "        print(f'Training - Loss: {avg_train_loss:.4f}, Recon: {avg_train_recon:.4f}, KL: {avg_train_kl:.4f}')\n",
        "        print(f'Validation - Loss: {val_loss:.4f}, Recon: {val_recon:.4f}, KL: {val_kl:.4f}\\n')\n",
        "\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['train_recon'].append(avg_train_recon)\n",
        "        history['train_kl'].append(avg_train_kl)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_recon'].append(val_recon)\n",
        "        history['val_kl'].append(val_kl)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            save_path = os.path.join(save_dir, f'vae_{args.modality}_best_{timestamp}.pt')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': vae.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'history': history\n",
        "            }, save_path)\n",
        "            print(f'Saved best model to {save_path}')\n",
        "            torch.save(vae.state_dict(), f\"/content/best_trained_vae_{args.modality}.pkl\")\n",
        "\n",
        "\n",
        "        # Early stopping\n",
        "        if early_stopping(val_loss):\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return vae"
      ],
      "metadata": {
        "id": "vE72-3Wu258p"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run for pretraining multimodal VAE"
      ],
      "metadata": {
        "id": "5kDWRPruuioi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust args needed for VAE\n",
        "args_vae = Args()\n",
        "args_vae.feature_size = 1152  # 1024 (RGB) + 128 (audio)\n",
        "args_vae.batch_size = 64\n",
        "args_vae.modality = 'MIX2'\n",
        "args_vae.max_epoch = 500\n",
        "args_vae.lr = 0.0005\n",
        "\n",
        "# initialize VAE with correct input dimension\n",
        "vae = VAE(latent_dim=64, input_dim=args_vae.feature_size, seq_len=200)\n",
        "\n",
        "# Create normal-only dataloaders\n",
        "normal_train_loader, normal_val_loader, normal_test_loader = create_normal_data_loaders(args_vae)\n",
        "\n",
        "# Train the VAE\n",
        "trained_vae = train_vae(vae, normal_train_loader, normal_val_loader, args_vae)\n",
        "# Save the model (adjust path name for modality)\n",
        "#torch.save(trained_vae.state_dict(), \"/content/last_trained_vae.pkl\")"
      ],
      "metadata": {
        "id": "Kfk8AUIdA3tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp '/content/best_trained_vae.pkl' ./vae_checkpoints/"
      ],
      "metadata": {
        "id": "t1GGuUOfNw2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run for pretraining VAE on RGB single modality data"
      ],
      "metadata": {
        "id": "uX4EL6fMvTUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust args needed for VAE\n",
        "args_vae = Args()\n",
        "args_vae.feature_size = 1024  # 1024 (RGB) + 128 (audio)\n",
        "args_vae.batch_size = 64\n",
        "args_vae.modality = 'RGB'\n",
        "args_vae.max_epoch = 500\n",
        "args_vae.lr = 0.0005\n",
        "\n",
        "# initialize VAE with correct input dimension\n",
        "vae = VAE(latent_dim=64, input_dim=args_vae.feature_size, seq_len=200)\n",
        "\n",
        "# Create normal-only dataloaders\n",
        "normal_train_loader, normal_val_loader, normal_test_loader = create_normal_data_loaders(args_vae)\n",
        "\n",
        "# Train the VAE\n",
        "trained_vae = train_vae(vae, normal_train_loader, normal_val_loader, args_vae)\n",
        "# Save the model\n",
        "#torch.save(trained_vae.state_dict(), \"./last_trained_vae.pkl\")"
      ],
      "metadata": {
        "id": "BVVPTYMkvXAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run for pretraining VAE on RGB single modality data"
      ],
      "metadata": {
        "id": "Uxaa3i7owaZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust args needed for VAE\n",
        "args_vae = Args()\n",
        "args_vae.feature_size = 128  # 1024 (RGB) + 128 (audio)\n",
        "args_vae.batch_size = 64\n",
        "args_vae.modality = 'AUDIO'\n",
        "args_vae.max_epoch = 500\n",
        "args_vae.lr = 0.0005\n",
        "\n",
        "# initialize VAE with correct input dimension\n",
        "vae = VAE(latent_dim=64, input_dim=args_vae.feature_size, seq_len=200)\n",
        "\n",
        "# Create normal-only dataloaders\n",
        "normal_train_loader, normal_val_loader, normal_test_loader = create_normal_data_loaders(args_vae)\n",
        "\n",
        "# Train the VAE\n",
        "trained_vae = train_vae(vae, normal_train_loader, normal_val_loader, args_vae)\n",
        "# Save the model\n",
        "#torch.save(trained_vae.state_dict(), \"./last_trained_vae.pkl\")"
      ],
      "metadata": {
        "id": "ObCVu04ZwTZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training HL-Net and HL-Net + VAE\n",
        "\n",
        "Training just the HL-Net on different modalities and then we also will load the pre-trained VAE and training the HL-net receiving reconstruction signal from the pre-trained VAE"
      ],
      "metadata": {
        "id": "t23YiBw-TiNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-flight\n",
        "\n",
        "Classes, model, layers, utils for running the HL-Net"
      ],
      "metadata": {
        "id": "i9AXr6nozXBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "from torch import FloatTensor\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import torch.nn.init as torch_init\n",
        "import os\n",
        "\n",
        "def weight_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1 or classname.find('Linear') != -1:\n",
        "        torch_init.xavier_uniform_(m.weight)\n",
        "        # m.bias.data.fill_(0.1)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        n_features = args.feature_size\n",
        "        n_class = args.num_classes\n",
        "\n",
        "        self.conv1d1 = nn.Conv1d(in_channels=n_features, out_channels=512, kernel_size=1, padding=0)\n",
        "        self.conv1d2 = nn.Conv1d(in_channels=512, out_channels=128, kernel_size=1, padding=0)\n",
        "        self.conv1d3 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=5, padding=2)\n",
        "        self.conv1d4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
        "        # Graph Convolution\n",
        "        self.gc1 = GraphConvolution(128, 32, residual=True)  # nn.Linear(128, 32)\n",
        "        self.gc2 = GraphConvolution(32, 32, residual=True)\n",
        "        self.gc3 = GraphConvolution(128, 32, residual=True)  # nn.Linear(128, 32)\n",
        "        self.gc4 = GraphConvolution(32, 32, residual=True)\n",
        "        self.gc5 = GraphConvolution(128, 32, residual=True)  # nn.Linear(128, 32)\n",
        "        self.gc6 = GraphConvolution(32, 32, residual=True)\n",
        "        self.simAdj = SimilarityAdj(n_features, 32)\n",
        "        self.disAdj = DistanceAdj()\n",
        "\n",
        "        self.classifier = nn.Linear(32*3, n_class)\n",
        "        self.approximator = nn.Sequential(nn.Conv1d(128, 64, 1, padding=0), nn.ReLU(),\n",
        "                                          nn.Conv1d(64, 32, 1, padding=0), nn.ReLU())\n",
        "        self.conv1d_approximator = nn.Conv1d(32, 1, 5, padding=0)\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.apply(weight_init)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs, seq_len):\n",
        "        x = inputs.permute(0, 2, 1)  # for conv1d\n",
        "        x = self.relu(self.conv1d1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.conv1d2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logits = self.approximator(x)\n",
        "        logits = F.pad(logits, (4, 0))\n",
        "        logits = self.conv1d_approximator(logits)\n",
        "        logits = logits.permute(0, 2, 1)\n",
        "        x = x.permute(0, 2, 1)  # b*t*c\n",
        "\n",
        "        ## gcn\n",
        "        scoadj = self.sadj(logits.detach(), seq_len)\n",
        "        adj = self.adj(inputs, seq_len)\n",
        "        disadj = self.disAdj(x.shape[0], x.shape[1])\n",
        "        x1_h = self.relu(self.gc1(x, adj))\n",
        "        x1_h = self.dropout(x1_h)\n",
        "        x2_h = self.relu(self.gc3(x, disadj))\n",
        "        x2_h = self.dropout(x2_h)\n",
        "        x3_h = self.relu(self.gc5(x, scoadj))\n",
        "        x3_h = self.dropout(x3_h)\n",
        "        x1 = self.relu(self.gc2(x1_h, adj))\n",
        "        x1 = self.dropout(x1)\n",
        "        x2 = self.relu(self.gc4(x2_h, disadj))\n",
        "        x2 = self.dropout(x2)\n",
        "        x3 = self.relu(self.gc6(x3_h, scoadj))\n",
        "        x3 = self.dropout(x3)\n",
        "        x = torch.cat((x1, x2, x3), 2)\n",
        "        x = self.classifier(x)\n",
        "        return x, logits\n",
        "\n",
        "    def sadj(self, logits, seq_len):\n",
        "        lens = logits.shape[1]\n",
        "        soft = nn.Softmax(1)\n",
        "        logits2 = self.sigmoid(logits).repeat(1, 1, lens)\n",
        "        tmp = logits2.permute(0, 2, 1)\n",
        "        adj = 1. - torch.abs(logits2 - tmp)\n",
        "        self.sig = lambda x:1/(1+torch.exp(-((x-0.5))/0.1))\n",
        "        adj = self.sig(adj)\n",
        "        output = torch.zeros_like(adj)\n",
        "        if seq_len is None:\n",
        "            for i in range(logits.shape[0]):\n",
        "                tmp = adj[i]\n",
        "                adj2 = soft(tmp)\n",
        "                output[i] = adj2\n",
        "        else:\n",
        "            for i in range(len(seq_len)):\n",
        "                tmp = adj[i, :seq_len[i], :seq_len[i]]\n",
        "                adj2 = soft(tmp)\n",
        "                output[i, :seq_len[i], :seq_len[i]] = adj2\n",
        "        return output\n",
        "\n",
        "\n",
        "    def adj(self, x, seq_len):\n",
        "        soft = nn.Softmax(1)\n",
        "        x2 = x.matmul(x.permute(0,2,1)) # B*T*T\n",
        "        x_norm = torch.norm(x, p=2, dim=2, keepdim=True)  # B*T*1\n",
        "        x_norm_x = x_norm.matmul(x_norm.permute(0,2,1))\n",
        "        x2 = x2/(x_norm_x+1e-20)\n",
        "        output = torch.zeros_like(x2)\n",
        "        if seq_len is None:\n",
        "            for i in range(x.shape[0]):\n",
        "                tmp = x2[i]\n",
        "                adj2 = tmp\n",
        "                adj2 = F.threshold(adj2, 0.7, 0)\n",
        "                adj2 = soft(adj2)\n",
        "                output[i] = adj2\n",
        "        else:\n",
        "            for i in range(len(seq_len)):\n",
        "                tmp = x2[i, :seq_len[i], :seq_len[i]]\n",
        "                adj2 = tmp\n",
        "                adj2 = F.threshold(adj2, 0.7, 0)\n",
        "                adj2 = soft(adj2)\n",
        "                output[i, :seq_len[i], :seq_len[i]] = adj2\n",
        "\n",
        "        return output\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
        "        super(GraphAttentionLayer, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Parameter(nn.init.xavier_uniform(torch.Tensor(in_features, out_features).type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor), gain=np.sqrt(2.0)), requires_grad=True)\n",
        "        self.a = nn.Parameter(nn.init.xavier_uniform(torch.Tensor(2*out_features, 1).type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor), gain=np.sqrt(2.0)), requires_grad=True)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        h = torch.mm(input, self.W)\n",
        "        N = h.size()[0]\n",
        "\n",
        "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)\n",
        "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
        "\n",
        "        zero_vec = -9e15*torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "        h_prime = torch.matmul(attention, h)\n",
        "\n",
        "        if self.concat:\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            return h_prime\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
        "\n",
        "class linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(linear, self).__init__()\n",
        "        self.weight = Parameter(FloatTensor(in_features, out_features))\n",
        "        self.register_parameter('bias', None)\n",
        "        stdv = 1. / sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "    def forward(self, x):\n",
        "        x = x.matmul(self.weight)\n",
        "        return x\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=False, residual=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(FloatTensor(in_features, out_features))\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "        if not residual:\n",
        "            self.residual = lambda x: 0\n",
        "        elif (in_features == out_features):\n",
        "            self.residual = lambda x: x\n",
        "        else:\n",
        "            # self.residual = linear(in_features, out_features)\n",
        "            self.residual = nn.Conv1d(in_channels=in_features, out_channels=out_features, kernel_size=5, padding=2)\n",
        "    def reset_parameters(self):\n",
        "        # stdv = 1. / sqrt(self.weight.size(1))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        # To support batch operations\n",
        "        support = input.matmul(self.weight)\n",
        "        output = adj.matmul(support)\n",
        "\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.in_features != self.out_features and self.residual:\n",
        "            input = input.permute(0,2,1)\n",
        "            res = self.residual(input)\n",
        "            res = res.permute(0,2,1)\n",
        "            output = output + res\n",
        "        else:\n",
        "            output = output + self.residual(input)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "######################################################\n",
        "\n",
        "class SimilarityAdj(Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(SimilarityAdj, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.weight0 = Parameter(FloatTensor(in_features, out_features))\n",
        "        self.weight1 = Parameter(FloatTensor(in_features, out_features))\n",
        "        self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # stdv = 1. / sqrt(self.weight0.size(1))\n",
        "        nn.init.xavier_uniform_(self.weight0)\n",
        "        nn.init.xavier_uniform_(self.weight1)\n",
        "\n",
        "    def forward(self, input, seq_len):\n",
        "        # To support batch operations\n",
        "        soft = nn.Softmax(1)\n",
        "        theta = torch.matmul(input, self.weight0)\n",
        "        phi = torch.matmul(input, self.weight0)\n",
        "        phi2 = phi.permute(0, 2, 1)\n",
        "        sim_graph = torch.matmul(theta, phi2)\n",
        "\n",
        "        theta_norm = torch.norm(theta, p=2, dim=2, keepdim=True)  # B*T*1\n",
        "        phi_norm = torch.norm(phi, p=2, dim=2, keepdim=True)  # B*T*1\n",
        "        x_norm_x = theta_norm.matmul(phi_norm.permute(0, 2, 1))\n",
        "        sim_graph = sim_graph / (x_norm_x + 1e-20)\n",
        "\n",
        "        output = torch.zeros_like(sim_graph)\n",
        "        if seq_len is None:\n",
        "            for i in range(sim_graph.shape[0]):\n",
        "                tmp = sim_graph[i]\n",
        "                adj2 = tmp\n",
        "                adj2 = F.threshold(adj2, 0.7, 0)\n",
        "                adj2 = soft(adj2)\n",
        "                output[i] = adj2\n",
        "        else:\n",
        "            for i in range(len(seq_len)):\n",
        "                tmp = sim_graph[i, :seq_len[i], :seq_len[i]]\n",
        "                adj2 = tmp\n",
        "                adj2 = F.threshold(adj2, 0.7, 0)\n",
        "                adj2 = soft(adj2)\n",
        "                output[i, :seq_len[i], :seq_len[i]] = adj2\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "class DistanceAdj(Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DistanceAdj, self).__init__()\n",
        "        self.sigma = Parameter(FloatTensor(1))\n",
        "        self.sigma.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, batch_size, max_seqlen):\n",
        "        # To support batch operations\n",
        "        self.arith = np.arange(max_seqlen).reshape(-1, 1)\n",
        "        dist = pdist(self.arith, metric='cityblock').astype(np.float32)\n",
        "        self.dist = torch.from_numpy(squareform(dist)).to('cuda')\n",
        "        self.dist = torch.exp(-self.dist / torch.exp(torch.tensor(1.)))\n",
        "        self.dist = torch.unsqueeze(self.dist, 0).repeat(batch_size, 1, 1).to('cuda')\n",
        "        return self.dist\n",
        "\n",
        "def CLAS(logits, label, seq_len, criterion, device, is_topk=True):\n",
        "    logits = logits.squeeze()\n",
        "    instance_logits = torch.zeros(0).to(device)  # tensor([])\n",
        "    for i in range(logits.shape[0]):\n",
        "        if is_topk:\n",
        "            tmp, _ = torch.topk(logits[i][:seq_len[i]], k=int(seq_len[i]//16+1), largest=True)\n",
        "            tmp = torch.mean(tmp).view(1)\n",
        "        else:\n",
        "            tmp = torch.mean(logits[i, :seq_len[i]]).view(1)\n",
        "        instance_logits = torch.cat((instance_logits, tmp))\n",
        "\n",
        "    instance_logits = torch.sigmoid(instance_logits)\n",
        "\n",
        "    clsloss = criterion(instance_logits, label)\n",
        "    return clsloss\n",
        "\n",
        "\n",
        "def CENTROPY(logits, logits2, seq_len, device):\n",
        "    instance_logits = torch.tensor(0).to(device)  # tensor([])\n",
        "    for i in range(logits.shape[0]):\n",
        "        tmp1 = torch.sigmoid(logits[i, :seq_len[i]]).squeeze()\n",
        "        tmp2 = torch.sigmoid(logits2[i, :seq_len[i]]).squeeze()\n",
        "        loss = torch.mean(-tmp1.detach() * torch.log(tmp2))\n",
        "        instance_logits = instance_logits + loss\n",
        "    instance_logits = instance_logits/logits.shape[0]\n",
        "    return instance_logits\n",
        "\n",
        "def create_data_loaders(args):\n",
        "    \"\"\"\n",
        "    Create train, validation and test data loaders\n",
        "    \"\"\"\n",
        "    print(\"Creating data loaders...\")\n",
        "\n",
        "    # Create train loader\n",
        "    train_dataset = Dataset(args, mode='train')\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Train loader created with {len(train_dataset)} samples\")\n",
        "\n",
        "    # Create validation loader\n",
        "    val_dataset = Dataset(args, mode='val')\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,  # No need to shuffle validation data\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Validation loader created with {len(val_dataset)} samples\")\n",
        "\n",
        "    # Create test loader with smaller batch size as per original code\n",
        "    test_dataset = Dataset(args, mode='test')\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=5,  # Using smaller batch size for testing\n",
        "        shuffle=False,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "WRKGPRTfzgqr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting\n",
        "this is called a lot down below, you can adjust the plot commands here"
      ],
      "metadata": {
        "id": "if_vklgpNdY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(train_losses, val_losses, save_path='hl-vae-training_history.png'):\n",
        "    \"\"\"\n",
        "    Plot training and validation losses over epochs.\n",
        "\n",
        "    Args:\n",
        "        train_losses (list): List of training losses per epoch\n",
        "        val_losses (list): List of validation losses per epoch\n",
        "        save_path (str): Path to save the plot\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    epochs = range(len(train_losses))\n",
        "\n",
        "    plt.plot(epochs, train_losses, 'b-o', label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, 'r-o', label='Validation Loss')\n",
        "\n",
        "    plt.title('')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Adjust layout to prevent label cutoff\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "XICuASeVNcnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HL-Net Training Multimodal (with no VAE)"
      ],
      "metadata": {
        "id": "_cnDUWwO4nUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import auc, precision_recall_curve\n",
        "import time\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_state_dict = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "    def get_best_model_state(self):\n",
        "        return self.best_state_dict\n",
        "\n",
        "def validate_epoch(val_loader, model, criterion, device, is_topk):\n",
        "    \"\"\"Run validation for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input, label in val_loader:\n",
        "            seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "            input = input[:, :torch.max(seq_len), :]\n",
        "            input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "            logits, logits2 = model(input, seq_len)\n",
        "            clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "            clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "            croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "            total_loss += (clsloss + clsloss2 + 5*croloss).item()\n",
        "            batch_count += 1\n",
        "\n",
        "    return total_loss / batch_count\n",
        "\n",
        "def test_hlnet(dataloader, model, device):\n",
        "    \"\"\"Test function that evaluates video-level predictions\"\"\"\n",
        "    print(\"Starting test...\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        pred = []\n",
        "        pred2 = []\n",
        "        gt = []\n",
        "\n",
        "        for i, (input, label) in enumerate(dataloader):\n",
        "            gt.append(label[0].item())\n",
        "            input = input.to(device)\n",
        "            logits, logits2 = model(inputs=input, seq_len=None)\n",
        "\n",
        "            # Get predictions for offline model\n",
        "            logits = torch.squeeze(logits)\n",
        "            sig = torch.sigmoid(logits)\n",
        "            batch_pred = torch.mean(sig).item()\n",
        "            pred.append(batch_pred)\n",
        "\n",
        "            # Get predictions for online model\n",
        "            logits2 = torch.squeeze(logits2)\n",
        "            sig2 = torch.sigmoid(logits2)\n",
        "            batch_pred2 = torch.mean(sig2).item()\n",
        "            pred2.append(batch_pred2)\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        gt = np.array(gt)\n",
        "        pred = np.array(pred)\n",
        "        pred2 = np.array(pred2)\n",
        "        precision, recall, _ = precision_recall_curve(gt, pred)\n",
        "        pr_auc = auc(recall, precision)\n",
        "\n",
        "        precision2, recall2, _ = precision_recall_curve(gt, pred2)\n",
        "        pr_auc2 = auc(recall2, precision2)\n",
        "\n",
        "        return pr_auc, pr_auc2\n",
        "\n",
        "def train_hlnet(train_loader, model, optimizer, scheduler, criterion,\n",
        "                device, is_topk, val_loader=None):\n",
        "    \"\"\"Training function with loss tracking\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(train_loader):\n",
        "        seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "        input = input[:, :torch.max(seq_len), :]\n",
        "        input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "        logits, logits2 = model(input, seq_len)\n",
        "        clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "        clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "        croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "        total_loss = clsloss + clsloss2 + 5*croloss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += total_loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Step {i+1}: Training Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / batch_count\n",
        "\n",
        "    # Calculate validation loss if provided\n",
        "    val_epoch_loss = None\n",
        "    if val_loader is not None:\n",
        "        val_epoch_loss = validate_epoch(val_loader, model, criterion, device, is_topk)\n",
        "\n",
        "    return model, avg_epoch_loss, val_epoch_loss\n"
      ],
      "metadata": {
        "id": "un7SHBGU4kxQ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize settings\n",
        "args = Args()\n",
        "args.max_epoch = 200\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create model and move to device\n",
        "model = Model(args).to(device)\n",
        "\n",
        "# Setup optimizer\n",
        "approximator_param = list(map(id, model.approximator.parameters()))\n",
        "approximator_param += list(map(id, model.conv1d_approximator.parameters()))\n",
        "base_param = filter(lambda p: id(p) not in approximator_param, model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': base_param},\n",
        "    {'params': model.approximator.parameters(), 'lr': args.lr / 2},\n",
        "    {'params': model.conv1d_approximator.parameters(), 'lr': args.lr / 2},\n",
        "], lr=args.lr, weight_decay=0.000)\n",
        "\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "is_topk = True\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, val_loader, test_loader = create_data_loaders(args)\n",
        "\n",
        "# Initialize early stopping\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "\n",
        "# Training tracking\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_pr_auc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"Starting training on {device}\")\n",
        "\n",
        "for epoch in range(args.max_epoch):\n",
        "    print(f\"\\nEpoch {epoch+1}/{args.max_epoch}\")\n",
        "    st = time.time()\n",
        "\n",
        "    # Training step\n",
        "    model, train_loss, val_loss = train_hlnet(\n",
        "        train_loader=train_loader,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        is_topk=is_topk,\n",
        "        val_loader=val_loader\n",
        "    )\n",
        "\n",
        "    # Store losses\n",
        "    train_losses.append(train_loss)\n",
        "    if val_loss is not None:\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    pr_auc, pr_auc_online = test_hlnet(test_loader, model, device)\n",
        "\n",
        "    if pr_auc > best_pr_auc:\n",
        "        best_pr_auc = pr_auc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    if val_loss is not None:\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'PR-AUC (Offline/Online): {pr_auc:.4f}/{pr_auc_online:.4f}')\n",
        "    print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n",
        "    print(f'Epoch time: {time.time() - st:.2f}s')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        model.load_state_dict(early_stopping.get_best_model_state())\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save checkpoint every 5 epochs\n",
        "    if epoch % 5 == 0 and epoch > 0:\n",
        "        save_dir = './only_hlnet_saves_mm/checkpoints'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        torch.save(model.state_dict(), f'{save_dir}/{args.model_name}_epoch{epoch}.pth')\n",
        "\n",
        "# Save final model\n",
        "save_dir = './only_hlnet_saves_mm/final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), f'{save_dir}/{args.model_name}_final.pth')\n",
        "\n",
        "# Plot and save training history\n",
        "plot_training_history(train_losses, val_losses, save_path='only_hlnet_training_history.png')\n",
        "\n",
        "# Final evaluation\n",
        "final_pr_auc, final_pr_auc_online = test_hlnet(test_loader, model, device)\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f'Final PR-AUC (Offline/Online): {final_pr_auc:.4f}/{final_pr_auc_online:.4f}')\n",
        "print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n"
      ],
      "metadata": {
        "id": "C7WK7tHU5kAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HLNet Training RGB (single modality, no VAE)"
      ],
      "metadata": {
        "id": "bT6hTfCt9ADz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import auc, precision_recall_curve\n",
        "import time\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_state_dict = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "    def get_best_model_state(self):\n",
        "        return self.best_state_dict\n",
        "\n",
        "def validate_epoch(val_loader, model, criterion, device, is_topk):\n",
        "    \"\"\"Run validation for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input, label in val_loader:\n",
        "            seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "            input = input[:, :torch.max(seq_len), :]\n",
        "            input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "            logits, logits2 = model(input, seq_len)\n",
        "            clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "            clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "            croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "            total_loss += (clsloss + clsloss2 + 5*croloss).item()\n",
        "            batch_count += 1\n",
        "\n",
        "    return total_loss / batch_count\n",
        "\n",
        "def test_hlnet_single(dataloader, model, device):\n",
        "    \"\"\"Test function that evaluates video-level predictions\"\"\"\n",
        "    print(\"Starting test...\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        pred = []\n",
        "        pred2 = []\n",
        "        gt = []\n",
        "\n",
        "        for i, (input, label) in enumerate(dataloader):\n",
        "            gt.append(label[0].item())  # Take first label as they're all same for a video\n",
        "\n",
        "            input = input.to(device)\n",
        "            logits, logits2 = model(inputs=input, seq_len=None)\n",
        "\n",
        "            # Get predictions for offline model\n",
        "            logits = torch.squeeze(logits)\n",
        "            sig = torch.sigmoid(logits)\n",
        "            batch_pred = torch.mean(sig).item()\n",
        "            pred.append(batch_pred)\n",
        "\n",
        "            # Get predictions for online model\n",
        "            logits2 = torch.squeeze(logits2)\n",
        "            sig2 = torch.sigmoid(logits2)\n",
        "            batch_pred2 = torch.mean(sig2).item()\n",
        "            pred2.append(batch_pred2)\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        gt = np.array(gt)\n",
        "        pred = np.array(pred)\n",
        "        pred2 = np.array(pred2)\n",
        "\n",
        "        # Calculate metrics\n",
        "        precision, recall, _ = precision_recall_curve(gt, pred)\n",
        "        pr_auc = auc(recall, precision)\n",
        "\n",
        "        precision2, recall2, _ = precision_recall_curve(gt, pred2)\n",
        "        pr_auc2 = auc(recall2, precision2)\n",
        "\n",
        "        return pr_auc, pr_auc2\n",
        "\n",
        "def train_hlnet_single(train_loader, model, optimizer, scheduler, criterion,\n",
        "                      device, is_topk, val_loader=None):\n",
        "    \"\"\"Training function with loss tracking\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(train_loader):\n",
        "        seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "        input = input[:, :torch.max(seq_len), :]\n",
        "        input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "        logits, logits2 = model(input, seq_len)\n",
        "        clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "        clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "        croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "        total_loss = clsloss + clsloss2 + 5*croloss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += total_loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Step {i+1}: Training Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / batch_count\n",
        "\n",
        "    # Calculate validation loss if provided\n",
        "    val_epoch_loss = None\n",
        "    if val_loader is not None:\n",
        "        val_epoch_loss = validate_epoch(val_loader, model, criterion, device, is_topk)\n",
        "\n",
        "    return model, avg_epoch_loss, val_epoch_loss"
      ],
      "metadata": {
        "id": "jQJrN2b_9RiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Args()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.modality = 'RGB'\n",
        "args.max_epoch = 200\n",
        "# Set feature size based on modality\n",
        "if args.modality == 'RGB':\n",
        "    args.feature_size = 1024\n",
        "elif args.modality == 'AUDIO':\n",
        "    args.feature_size = 128\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported modality: {args.modality}\")\n",
        "\n",
        "# Create model and move to device\n",
        "model = Model(args).to(device)\n",
        "\n",
        "# Setup optimizer\n",
        "approximator_param = list(map(id, model.approximator.parameters()))\n",
        "approximator_param += list(map(id, model.conv1d_approximator.parameters()))\n",
        "base_param = filter(lambda p: id(p) not in approximator_param, model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': base_param},\n",
        "    {'params': model.approximator.parameters(), 'lr': args.lr / 2},\n",
        "    {'params': model.conv1d_approximator.parameters(), 'lr': args.lr / 2},\n",
        "], lr=args.lr, weight_decay=0.000)\n",
        "\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "is_topk = True\n",
        "\n",
        "# Create data loaders using your existing function\n",
        "train_loader, val_loader, test_loader = create_single_modality_data_loaders(args)\n",
        "\n",
        "# Initialize early stopping\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "\n",
        "# Training tracking\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_pr_auc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"Starting training on {device} for {args.modality} modality\")\n",
        "\n",
        "for epoch in range(args.max_epoch):\n",
        "    print(f\"\\nEpoch {epoch+1}/{args.max_epoch}\")\n",
        "    st = time.time()\n",
        "\n",
        "    # Training step\n",
        "    model, train_loss, val_loss = train_hlnet_single(\n",
        "        train_loader=train_loader,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        is_topk=is_topk,\n",
        "        val_loader=val_loader\n",
        "    )\n",
        "\n",
        "    # Store losses\n",
        "    train_losses.append(train_loss)\n",
        "    if val_loss is not None:\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Calculate PR-AUC for monitoring\n",
        "    pr_auc, pr_auc_online = test_hlnet_single(test_loader, model, device)\n",
        "\n",
        "    # Update best PR-AUC\n",
        "    if pr_auc > best_pr_auc:\n",
        "        best_pr_auc = pr_auc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    if val_loss is not None:\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'PR-AUC (Offline/Online): {pr_auc:.4f}/{pr_auc_online:.4f}')\n",
        "    print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n",
        "    print(f'Epoch time: {time.time() - st:.2f}s')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        model.load_state_dict(early_stopping.get_best_model_state())\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save checkpoint every 5 epochs\n",
        "    if epoch % 5 == 0 and epoch > 0:\n",
        "        save_dir = f'./only_hlnet_saves_{args.modality.lower()}/checkpoints'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        torch.save(model.state_dict(),\n",
        "                  f'{save_dir}/{args.model_name}_epoch{epoch}.pth')\n",
        "\n",
        "# Save final model\n",
        "save_dir = f'./only_hlnet_saves_{args.modality.lower()}/final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(),\n",
        "          f'{save_dir}/{args.model_name}_final.pth')\n",
        "\n",
        "# Plot and save training history\n",
        "plot_training_history(train_losses, val_losses, save_path='only_hlnet_rgb_training_history.png')\n",
        "\n",
        "# Final evaluation\n",
        "final_pr_auc, final_pr_auc_online = test_hlnet_single(test_loader, model, device)\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f'Final PR-AUC (Offline/Online): {final_pr_auc:.4f}/{final_pr_auc_online:.4f}')\n",
        "print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n"
      ],
      "metadata": {
        "id": "IKdZIBIW_WwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HLNet Training Audio (single modality, no VAE)"
      ],
      "metadata": {
        "id": "xR_fo5bc9LVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = Args()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.modality = 'AUDIO'\n",
        "args.max_epoch = 200\n",
        "# Set feature size based on modality\n",
        "if args.modality == 'RGB':\n",
        "    args.feature_size = 1024\n",
        "elif args.modality == 'AUDIO':\n",
        "    args.feature_size = 128\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported modality: {args.modality}\")\n",
        "\n",
        "# Create model and move to device\n",
        "model = Model(args).to(device)\n",
        "\n",
        "# Setup optimizer\n",
        "approximator_param = list(map(id, model.approximator.parameters()))\n",
        "approximator_param += list(map(id, model.conv1d_approximator.parameters()))\n",
        "base_param = filter(lambda p: id(p) not in approximator_param, model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': base_param},\n",
        "    {'params': model.approximator.parameters(), 'lr': args.lr / 2},\n",
        "    {'params': model.conv1d_approximator.parameters(), 'lr': args.lr / 2},\n",
        "], lr=args.lr, weight_decay=0.000)\n",
        "\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "is_topk = True\n",
        "\n",
        "# Create data loaders using your existing function\n",
        "train_loader, val_loader, test_loader = create_single_modality_data_loaders(args)\n",
        "\n",
        "# Initialize early stopping\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "\n",
        "# Training tracking\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_pr_auc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "print(f\"Starting training on {device} for {args.modality} modality\")\n",
        "\n",
        "for epoch in range(args.max_epoch):\n",
        "    print(f\"\\nEpoch {epoch+1}/{args.max_epoch}\")\n",
        "    st = time.time()\n",
        "\n",
        "    # Training step\n",
        "    model, train_loss, val_loss = train_hlnet_single(\n",
        "        train_loader=train_loader,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        is_topk=is_topk,\n",
        "        val_loader=val_loader\n",
        "    )\n",
        "\n",
        "    # Store losses\n",
        "    train_losses.append(train_loss)\n",
        "    if val_loss is not None:\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Calculate PR-AUC for monitoring\n",
        "    pr_auc, pr_auc_online = test_hlnet_single(test_loader, model, device)\n",
        "\n",
        "    # Update best PR-AUC\n",
        "    if pr_auc > best_pr_auc:\n",
        "        best_pr_auc = pr_auc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    if val_loss is not None:\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'PR-AUC (Offline/Online): {pr_auc:.4f}/{pr_auc_online:.4f}')\n",
        "    print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n",
        "    print(f'Epoch time: {time.time() - st:.2f}s')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        model.load_state_dict(early_stopping.get_best_model_state())\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save checkpoint every 5 epochs\n",
        "    if epoch % 5 == 0 and epoch > 0:\n",
        "        save_dir = f'./only_hlnet_saves_{args.modality.lower()}/checkpoints'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        torch.save(model.state_dict(),\n",
        "                  f'{save_dir}/{args.model_name}_epoch{epoch}.pth')\n",
        "\n",
        "# Save final model\n",
        "save_dir = f'./only_hlnet_saves_{args.modality.lower()}/final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(),\n",
        "          f'{save_dir}/{args.model_name}_final.pth')\n",
        "\n",
        "# Plot and save training history\n",
        "plot_training_history(train_losses, val_losses, save_path='only_hlnet_audio_training_history.png'))\n",
        "\n",
        "# Final evaluation\n",
        "final_pr_auc, final_pr_auc_online = test_hlnet_single(test_loader, model, device)\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f'Final PR-AUC (Offline/Online): {final_pr_auc:.4f}/{final_pr_auc_online:.4f}')\n",
        "print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n"
      ],
      "metadata": {
        "id": "sFHLrBAd9R_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train HL-Net + VAE (Multimodal: Audio + RGB)"
      ],
      "metadata": {
        "id": "MArlBOBwT695"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import auc, precision_recall_curve\n",
        "import time\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0, verbose=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Number of epochs to wait before stopping if no improvement\n",
        "            min_delta (float): Minimum change in monitored value to qualify as an improvement\n",
        "            verbose (bool): If True, prints out early stopping information\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_state_dict = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "    def get_best_model_state(self):\n",
        "        return self.best_state_dict\n",
        "\n",
        "\n",
        "def validate_epoch(val_loader, hlnet, vae, criterion, device, is_topk,\n",
        "                  HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT):\n",
        "    \"\"\"Run validation for one epoch\"\"\"\n",
        "    hlnet.eval()\n",
        "    vae.eval()\n",
        "    total_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input, label in val_loader:\n",
        "            inputcpy = input.float().to(device)\n",
        "            seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "            input = input[:, :torch.max(seq_len), :]\n",
        "            input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "            logits, logits2 = hlnet(input, seq_len)\n",
        "            clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "            clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "            croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "            recon_data, mu, logvar = vae(inputcpy)\n",
        "            recon_criterion = torch.nn.MSELoss(reduction='mean')\n",
        "            recon_loss = recon_criterion(recon_data, inputcpy)\n",
        "\n",
        "            total_loss += (HLNET_LOSS_WEIGHT * (clsloss + clsloss2 + 5*croloss) +\n",
        "                         RECON_LOSS_WEIGHT * recon_loss).item()\n",
        "            batch_count += 1\n",
        "\n",
        "    return total_loss / batch_count\n",
        "\n",
        "def test_hl_vae(dataloader, model, device):\n",
        "    \"\"\"\n",
        "    Test function for HL-Net that evaluates video-level predictions\n",
        "    Returns PR-AUC scores for both offline and online predictions\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    video_gt = []\n",
        "    video_pred = []\n",
        "    video_pred2 = []\n",
        "\n",
        "    current_video_preds = []\n",
        "    current_video_preds2 = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (input, label) in enumerate(dataloader):\n",
        "            # Process input\n",
        "            input = input.to(device)\n",
        "            logits, logits2 = model(inputs=input, seq_len=None)\n",
        "\n",
        "            # Process predictions - average across time dimension first\n",
        "            logits = torch.squeeze(logits)  # Remove batch dim if batch_size=1\n",
        "            sig = torch.sigmoid(logits)\n",
        "            # Take mean across time dimension for each sample\n",
        "            sample_preds = torch.mean(sig, dim=1).cpu().numpy()\n",
        "            current_video_preds.extend(sample_preds)\n",
        "\n",
        "            logits2 = torch.squeeze(logits2)\n",
        "            sig2 = torch.sigmoid(logits2)\n",
        "            sample_preds2 = torch.mean(sig2, dim=1).cpu().numpy()\n",
        "            current_video_preds2.extend(sample_preds2)\n",
        "\n",
        "            # Every 5 frames, compute video-level prediction\n",
        "            if (i + 1) % 5 == 0:\n",
        "                # Take mean of the 5 frame predictions for this video\n",
        "                video_pred.append(np.mean(current_video_preds[-5:]))\n",
        "                video_pred2.append(np.mean(current_video_preds2[-5:]))\n",
        "                # Only take one label per video (they're all the same)\n",
        "                video_gt.append(label[0].item())\n",
        "                # Reset for next video\n",
        "                current_video_preds = []\n",
        "                current_video_preds2 = []\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    video_gt = np.array(video_gt)\n",
        "    video_pred = np.array(video_pred)\n",
        "    video_pred2 = np.array(video_pred2)\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(video_gt, video_pred)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    precision2, recall2, _ = precision_recall_curve(video_gt, video_pred2)\n",
        "    pr_auc2 = auc(recall2, precision2)\n",
        "\n",
        "    return pr_auc, pr_auc2\n",
        "\n",
        "def train_hlnet_vae(train_loader, hlnet, vae, optimizer, scheduler, criterion,\n",
        "                    device, is_topk, HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT, val_loader=None):\n",
        "    \"\"\"Training function with loss tracking\"\"\"\n",
        "    hlnet.train()\n",
        "    vae.eval()\n",
        "    epoch_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(train_loader):\n",
        "        inputcpy = input.float().to(device)\n",
        "        seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "        input = input[:, :torch.max(seq_len), :]\n",
        "        input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "        logits, logits2 = hlnet(input, seq_len)\n",
        "        clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "        clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "        croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            recon_data, mu, logvar = vae(inputcpy)\n",
        "            recon_criterion = torch.nn.MSELoss(reduction='mean')\n",
        "            recon_loss = recon_criterion(recon_data, inputcpy)\n",
        "\n",
        "        total_loss = HLNET_LOSS_WEIGHT * (clsloss + clsloss2 + 5*croloss) + RECON_LOSS_WEIGHT * recon_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += total_loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Step {i+1}: Training Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / batch_count\n",
        "\n",
        "    # Calculate validation loss if provided\n",
        "    val_epoch_loss = None\n",
        "    if val_loader is not None:\n",
        "        val_epoch_loss = validate_epoch(val_loader, hlnet, vae, criterion,\n",
        "                                      device, is_topk, HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT)\n",
        "\n",
        "    return hlnet, avg_epoch_loss, val_epoch_loss\n"
      ],
      "metadata": {
        "id": "Z7rHZOBd1CBi"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set the VAE model to load\n",
        "change line 9 to match the path of the VAE file you are loading"
      ],
      "metadata": {
        "id": "7GJ5HGbQ3GE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args_vae = Args()\n",
        "args_vae.feature_size = 1152\n",
        "args_vae.batch_size = 64\n",
        "args_vae.modality = 'MIX2'\n",
        "args_vae.max_epoch = 500\n",
        "args_vae.lr = 0.0005\n",
        "\n",
        "vae_model = VAE(latent_dim=64, input_dim=args_vae.feature_size, seq_len=200)\n",
        "dir = \"/mydrive/MyDrive/vae_checkpoints/best_trained_vae.pkl\" # Change this\n",
        "vae_model.load_state_dict(torch.load(dir))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vae_model = vae_model.cuda()\n",
        "vae_model.eval()\n",
        "\n",
        "HL_NET_LOSS_weight = .8\n",
        "RECON_LOSS_weight = .2\n",
        "\n",
        "args = Args()\n",
        "args.feature_size = 1152\n",
        "args.batch_size = 128\n",
        "args.modality = 'MIX2'\n",
        "args.max_seqlen = 200\n",
        "args.workers = 1\n",
        "args.max_epoch = 200\n",
        "\n",
        "train_loader, val_loader, test_loader = create_data_loaders(args)\n",
        "model = Model(args).to(device)\n",
        "\n",
        "approximator_param = list(map(id, model.approximator.parameters()))\n",
        "approximator_param += list(map(id, model.conv1d_approximator.parameters()))\n",
        "base_param = filter(lambda p: id(p) not in approximator_param, model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': base_param},\n",
        "    {'params': model.approximator.parameters(), 'lr': args.lr / 2},\n",
        "    {'params': model.conv1d_approximator.parameters(), 'lr': args.lr / 2},\n",
        "], lr=args.lr, weight_decay=0.000)\n",
        "\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "is_topk = True\n",
        "\n",
        "# Lists to store training history\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_pr_auc = 0\n",
        "best_epoch = 0\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "\n",
        "for epoch in range(args.max_epoch):\n",
        "    print(f\"\\nEpoch {epoch+1}/{args.max_epoch}\")\n",
        "    st = time.time()\n",
        "\n",
        "    # Training step\n",
        "    model, train_loss, val_loss = train_hlnet_vae(\n",
        "        train_loader=train_loader,\n",
        "        hlnet=model,\n",
        "        vae=vae_model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        is_topk=is_topk,\n",
        "        HLNET_LOSS_WEIGHT=HL_NET_LOSS_weight,\n",
        "        RECON_LOSS_WEIGHT=RECON_LOSS_weight,\n",
        "        val_loader=val_loader\n",
        "    )\n",
        "\n",
        "    # Store losses\n",
        "    train_losses.append(train_loss)\n",
        "    if val_loss is not None:\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Calculate PR-AUC for monitoring\n",
        "    pr_auc, pr_auc_online = test_hl_vae(test_loader, model, device)\n",
        "\n",
        "    # Update best PR-AUC\n",
        "    if pr_auc > best_pr_auc:\n",
        "        best_pr_auc = pr_auc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    if val_loss is not None:\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'PR-AUC (Offline/Online): {pr_auc:.4f}/{pr_auc_online:.4f}')\n",
        "    print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n",
        "    print(f'Epoch time: {time.time() - st:.2f}s')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        # Load the best model state\n",
        "        model.load_state_dict(early_stopping.get_best_model_state())\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch % 5 == 0 and epoch > 0:\n",
        "        save_dir = './hlnet_saves_mm'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        torch.save(model.state_dict(), f'{save_dir}/{args.model_name}{epoch}.pth')\n",
        "\n",
        "# Save final model\n",
        "save_dir = './hlnet_saves_mm/final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), f'{save_dir}/{args.model_name}{epoch}.pth')\n",
        "\n",
        "# Plot and save training history\n",
        "plot_training_history(train_losses, val_losses, save_path='hlnet_vae_training_history.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "Pmig59391BMJ",
        "outputId": "1951e930-89af-448e-a10e-5120047a21c1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-1cea92119f03>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vae_model.load_state_dict(torch.load(dir))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating data loaders...\n",
            "Train loader created with 15815 samples\n",
            "Validation loader created with 3955 samples\n",
            "Test loader created with 4000 samples\n",
            "\n",
            "Epoch 1/200\n",
            "Step 100: Training Loss: 1.2349\n",
            "Epoch 1/200:\n",
            "Train Loss: 1.5289\n",
            "Validation Loss: 1.7576\n",
            "PR-AUC (Offline/Online): 0.8281/0.9180\n",
            "Best PR-AUC: 0.8281 (Epoch 1)\n",
            "Epoch time: 281.91s\n",
            "\n",
            "Epoch 2/200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-1cea92119f03>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     model, train_loss, val_loss = train_hlnet_vae(\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mhlnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-e8c2154f24a4>\u001b[0m in \u001b[0;36mtrain_hlnet_vae\u001b[0;34m(train_loader, hlnet, vae, optimizer, scheduler, criterion, device, is_topk, HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT, val_loader)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhlnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mclsloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLAS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_topk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mclsloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLAS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_topk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mcroloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCENTROPY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-bcdf00d223c1>\u001b[0m in \u001b[0;36mCLAS\u001b[0;34m(logits, label, seq_len, criterion, device, is_topk)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_topk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# See https://github.com/pytorch/pytorch/issues/75462\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train HL-Net + VAE (RGB Only)"
      ],
      "metadata": {
        "id": "f58S4D8t17O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import auc, precision_recall_curve\n",
        "import time\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0, verbose=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Number of epochs to wait before stopping if no improvement\n",
        "            min_delta (float): Minimum change in monitored value to qualify as an improvement\n",
        "            verbose (bool): If True, prints out early stopping information\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_state_dict = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_state_dict = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "    def get_best_model_state(self):\n",
        "        return self.best_state_dict\n",
        "\n",
        "def validate_epoch(val_loader, hlnet, vae, criterion, device, is_topk,\n",
        "                  HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT):\n",
        "    hlnet.eval()\n",
        "    vae.eval()\n",
        "    total_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input, label in val_loader:\n",
        "            inputcpy = input.float().to(device)\n",
        "            seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "            input = input[:, :torch.max(seq_len), :]\n",
        "            input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "            logits, logits2 = hlnet(input, seq_len)\n",
        "            clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "            clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "            croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "            recon_data, mu, logvar = vae(inputcpy)\n",
        "            recon_criterion = torch.nn.MSELoss(reduction='mean')\n",
        "            recon_loss = recon_criterion(recon_data, inputcpy)\n",
        "\n",
        "            total_loss += (HLNET_LOSS_WEIGHT * (clsloss + clsloss2 + 5*croloss) +\n",
        "                         RECON_LOSS_WEIGHT * recon_loss).item()\n",
        "            batch_count += 1\n",
        "\n",
        "    return total_loss / batch_count\n",
        "\n",
        "def test_hl_vae(dataloader, model, device):\n",
        "    print(\"Starting test...\")\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        pred = []\n",
        "        pred2 = []\n",
        "        gt = []\n",
        "\n",
        "        for i, (input, label) in enumerate(dataloader):\n",
        "            if i == 0:  # Print shapes for first batch\n",
        "                print(f\"Input shape: {input.shape}\")\n",
        "                print(f\"Label shape: {label.shape}\")\n",
        "\n",
        "            # For ground truth, just take the label of first frame in batch\n",
        "            # (they should all be same for a video segment)\n",
        "            gt.append(label[0].item())\n",
        "\n",
        "            input = input.to(device)\n",
        "            logits, logits2 = model(inputs=input, seq_len=None)\n",
        "            if i == 0:\n",
        "                print(f\"Logits shape: {logits.shape}\")\n",
        "\n",
        "            # Get one prediction per batch/video segment\n",
        "            logits = torch.squeeze(logits)\n",
        "            sig = torch.sigmoid(logits)\n",
        "            if i == 0:\n",
        "                print(f\"Sig shape before mean: {sig.shape}\")\n",
        "\n",
        "            # Average over both frames and sequence length to get one score per video\n",
        "            batch_pred = torch.mean(sig).item()\n",
        "            pred.append(batch_pred)\n",
        "\n",
        "            # Same for online predictions\n",
        "            logits2 = torch.squeeze(logits2)\n",
        "            sig2 = torch.sigmoid(logits2)\n",
        "            batch_pred2 = torch.mean(sig2).item()\n",
        "            pred2.append(batch_pred2)\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        gt = np.array(gt)\n",
        "        pred = np.array(pred)\n",
        "        pred2 = np.array(pred2)\n",
        "\n",
        "        print(f\"Final shapes - GT: {gt.shape}, Pred: {pred.shape}, Pred2: {pred2.shape}\")\n",
        "\n",
        "        precision, recall, th = precision_recall_curve(gt, pred)\n",
        "        pr_auc = auc(recall, precision)\n",
        "        precision, recall, th = precision_recall_curve(gt, pred2)\n",
        "        pr_auc2 = auc(recall, precision)\n",
        "        return pr_auc, pr_auc2\n",
        "\n",
        "def train_hlnet_vae(train_loader, hlnet, vae, optimizer, scheduler, criterion,\n",
        "                    device, is_topk, HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT, val_loader=None):\n",
        "    hlnet.train()\n",
        "    vae.eval()\n",
        "    epoch_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    for i, (input, label) in enumerate(train_loader):\n",
        "        inputcpy = input.float().to(device)\n",
        "        seq_len = torch.sum(torch.max(torch.abs(input), dim=2)[0]>0, 1)\n",
        "        input = input[:, :torch.max(seq_len), :]\n",
        "        input, label = input.float().to(device), label.float().to(device)\n",
        "\n",
        "        logits, logits2 = hlnet(input, seq_len)\n",
        "        clsloss = CLAS(logits, label, seq_len, criterion, device, is_topk)\n",
        "        clsloss2 = CLAS(logits2, label, seq_len, criterion, device, is_topk)\n",
        "        croloss = CENTROPY(logits, logits2, seq_len, device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            recon_data, mu, logvar = vae(inputcpy)\n",
        "            recon_criterion = torch.nn.MSELoss(reduction='mean')\n",
        "            recon_loss = recon_criterion(recon_data, inputcpy)\n",
        "\n",
        "        total_loss = HLNET_LOSS_WEIGHT * (clsloss + clsloss2 + 5*croloss) + RECON_LOSS_WEIGHT * recon_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += total_loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Step {i+1}: Training Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / batch_count\n",
        "\n",
        "    val_epoch_loss = None\n",
        "    if val_loader is not None:\n",
        "        val_epoch_loss = validate_epoch(val_loader, hlnet, vae, criterion,\n",
        "                                      device, is_topk, HLNET_LOSS_WEIGHT, RECON_LOSS_WEIGHT)\n",
        "\n",
        "    return hlnet, avg_epoch_loss, val_epoch_loss\n",
        "\n",
        "class RgbDataset(data.Dataset):\n",
        "    def __init__(self, args, transform=None, mode='train'):\n",
        "        self.modality = args.modality\n",
        "        self.max_seqlen = args.max_seqlen\n",
        "        self.transform = transform\n",
        "        self.test_mode = (mode == 'test')\n",
        "\n",
        "        # Set appropriate file list based on mode\n",
        "        if mode == 'test':\n",
        "            self.rgb_list_file = args.test_rgb_list\n",
        "        elif mode == 'val':\n",
        "            self.rgb_list_file = args.val_rgb_list\n",
        "        else:  # train\n",
        "            self.rgb_list_file = args.train_rgb_list\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _parse_list(self):\n",
        "        self.list = [line.strip() for line in open(self.rgb_list_file)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file_path = self.list[index].strip()\n",
        "        features = np.array(np.load(file_path), dtype=np.float32)\n",
        "        label = 0.0 if '_label_A' in file_path else 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        features = process_feat(features, self.max_seqlen, is_random=not self.test_mode)\n",
        "        return features, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list)\n",
        "\n",
        "def rgbcreate_data_loaders(args):\n",
        "    \"\"\"\n",
        "    Create train, validation and test data loaders\n",
        "    \"\"\"\n",
        "    print(\"Creating data loaders...\")\n",
        "\n",
        "    # Create train loader\n",
        "    train_dataset = RgbDataset(args, mode='train')\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Train loader created with {len(train_dataset)} samples\")\n",
        "\n",
        "    # Create validation loader\n",
        "    val_dataset = RgbDataset(args, mode='val')\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,  # No need to shuffle validation data\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Validation loader created with {len(val_dataset)} samples\")\n",
        "\n",
        "    # Create test loader with smaller batch size as per original code\n",
        "    test_dataset = RgbDataset(args, mode='test')\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=5,  # Using smaller batch size for testing\n",
        "        shuffle=False,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "xjAZswKW2AH0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set the VAE model to load\n",
        "change line 9 to match the path of the VAE file you are loading"
      ],
      "metadata": {
        "id": "QgGkq3yk24Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args_vae = Args()\n",
        "args_vae.feature_size = 1024  # RGB feature size\n",
        "args_vae.batch_size = 64\n",
        "args_vae.modality = 'RGB'\n",
        "args_vae.max_epoch = 200\n",
        "args_vae.lr = 0.0005\n",
        "\n",
        "vae_model = VAE(latent_dim=64, input_dim=args_vae.feature_size, seq_len=200)\n",
        "vae_dir = \"/mydrive/MyDrive/single_modality/vae_checkpoints/best_trained_vae_RGB.pkl\" # CHANGE THIS\n",
        "vae_model.load_state_dict(torch.load(vae_dir))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vae_model = vae_model.to(device)\n",
        "vae_model.eval()\n",
        "\n",
        "HL_NET_LOSS_weight = 0.8\n",
        "RECON_LOSS_weight = 0.2\n",
        "\n",
        "# Initialize HL-Net\n",
        "args = Args()\n",
        "args.feature_size = 1024 # RGB Feature size\n",
        "args.max_epoch = 200\n",
        "model = Model(args).to(device)\n",
        "\n",
        "# Setup optimizer\n",
        "approximator_param = list(map(id, model.approximator.parameters()))\n",
        "approximator_param += list(map(id, model.conv1d_approximator.parameters()))\n",
        "base_param = filter(lambda p: id(p) not in approximator_param, model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': base_param},\n",
        "    {'params': model.approximator.parameters(), 'lr': args.lr / 2},\n",
        "    {'params': model.conv1d_approximator.parameters(), 'lr': args.lr / 2},\n",
        "], lr=args.lr, weight_decay=0.000)\n",
        "\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "is_topk = True\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_loader, val_loader, test_loader = rgbcreate_data_loaders(args)\n",
        "\n",
        "# Track losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_pr_auc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "for epoch in range(args.max_epoch):\n",
        "    print(f\"\\nEpoch {epoch+1}/{args.max_epoch}\")\n",
        "    st = time.time()\n",
        "\n",
        "    model, train_loss, val_loss = train_hlnet_vae(\n",
        "        train_loader=train_loader,\n",
        "        hlnet=model,\n",
        "        vae=vae_model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        is_topk=is_topk,\n",
        "        HLNET_LOSS_WEIGHT=HL_NET_LOSS_weight,\n",
        "        RECON_LOSS_WEIGHT=RECON_LOSS_weight,\n",
        "        val_loader=val_loader\n",
        "    )\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    if val_loss is not None:\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    pr_auc, pr_auc_online = test_hl_vae(test_loader, model, device)\n",
        "\n",
        "    if pr_auc > best_pr_auc:\n",
        "        best_pr_auc = pr_auc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    if val_loss is not None:\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'PR-AUC (Offline/Online): {pr_auc:.4f}/{pr_auc_online:.4f}')\n",
        "    print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n",
        "    print(f'Epoch time: {time.time() - st:.2f}s')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        # Load the best model state\n",
        "        model.load_state_dict(early_stopping.get_best_model_state())\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch % 5 == 0 and epoch > 0:\n",
        "        save_dir = './hlnet_saves_rgb'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        torch.save(model.state_dict(), f'{save_dir}/{args.model_name}{epoch}.pth')\n",
        "\n",
        "save_dir = './hlnet_saves_rgb/final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), f'{save_dir}/rgb_{args.model_name}{epoch}.pth')\n",
        "plot_training_history(train_losses, val_losses, save_path='hlnet_vae_rgb_training_history.png')\n"
      ],
      "metadata": {
        "id": "nWh6FRDm2uqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train HL-NET + VAE (AUDIO Only)"
      ],
      "metadata": {
        "id": "L21chcK0HCjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudDataset(data.Dataset):\n",
        "    def __init__(self, args, transform=None, mode='train'):\n",
        "        self.modality = args.modality\n",
        "        self.max_seqlen = args.max_seqlen\n",
        "        self.transform = transform\n",
        "        self.test_mode = (mode == 'test')\n",
        "\n",
        "        # Set appropriate file list based on mode\n",
        "        if mode == 'test':\n",
        "            self.audio_list_file = args.test_audio_list\n",
        "        elif mode == 'val':\n",
        "            self.audio_list_file = args.val_audio_list\n",
        "        else:  # train\n",
        "            self.audio_list_file = args.train_audio_list\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _parse_list(self):\n",
        "        self.list = [line.strip() for line in open(self.audio_list_file)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file_path = self.list[index].strip()\n",
        "        features = np.array(np.load(file_path), dtype=np.float32)\n",
        "        label = 0.0 if '_label_A' in file_path else 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        features = process_feat(features, self.max_seqlen, is_random=not self.test_mode)\n",
        "        return features, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list)\n",
        "\n",
        "def audcreate_data_loaders(args):\n",
        "    \"\"\"\n",
        "    Create train, validation and test data loaders\n",
        "    \"\"\"\n",
        "    print(\"Creating data loaders...\")\n",
        "\n",
        "    # Create train loader\n",
        "    train_dataset = AudDataset(args, mode='train')\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Train loader created with {len(train_dataset)} samples\")\n",
        "\n",
        "    # Create validation loader\n",
        "    val_dataset = AudDataset(args, mode='val')\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,  # No need to shuffle validation data\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Validation loader created with {len(val_dataset)} samples\")\n",
        "\n",
        "    # Create test loader with smaller batch size as per original code\n",
        "    test_dataset = AudDataset(args, mode='test')\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=5,  # Using smaller batch size for testing\n",
        "        shuffle=False,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    print(f\"Test loader created with {len(test_dataset)} samples\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "4xUd5FEeqBjW"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args_vae = Args()\n",
        "args_vae.feature_size = 128  # AUDIO feature size\n",
        "args_vae.batch_size = 64\n",
        "args_vae.modality = 'AUDIO'\n",
        "args_vae.max_epoch = 200\n",
        "args_vae.lr = 0.0005\n",
        "\n",
        "vae_model = VAE(latent_dim=64, input_dim=args_vae.feature_size, seq_len=200)\n",
        "vae_dir = \"/mydrive/MyDrive/single_modality/vae_checkpoints/best_trained_vae_AUDIO.pkl\" # CHANGE THIS\n",
        "vae_model.load_state_dict(torch.load(vae_dir))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vae_model = vae_model.to(device)\n",
        "vae_model.eval()\n",
        "\n",
        "HL_NET_LOSS_weight = 0.8\n",
        "RECON_LOSS_weight = 0.2\n",
        "\n",
        "# Initialize HL-Net\n",
        "args = Args()\n",
        "args.feature_size = 128 # AUDIO Feature size\n",
        "args.max_epoch = 200\n",
        "model = Model(args).to(device)\n",
        "\n",
        "# Setup optimizer\n",
        "approximator_param = list(map(id, model.approximator.parameters()))\n",
        "approximator_param += list(map(id, model.conv1d_approximator.parameters()))\n",
        "base_param = filter(lambda p: id(p) not in approximator_param, model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "    {'params': base_param},\n",
        "    {'params': model.approximator.parameters(), 'lr': args.lr / 2},\n",
        "    {'params': model.conv1d_approximator.parameters(), 'lr': args.lr / 2},\n",
        "], lr=args.lr, weight_decay=0.000)\n",
        "\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
        "criterion = torch.nn.BCELoss()\n",
        "is_topk = True\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_loader, val_loader, test_loader = audcreate_data_loaders(args)\n",
        "\n",
        "# Track losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_pr_auc = 0\n",
        "best_epoch = 0\n",
        "\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "for epoch in range(args.max_epoch):\n",
        "    print(f\"\\nEpoch {epoch+1}/{args.max_epoch}\")\n",
        "    st = time.time()\n",
        "\n",
        "    model, train_loss, val_loss = train_hlnet_vae(\n",
        "        train_loader=train_loader,\n",
        "        hlnet=model,\n",
        "        vae=vae_model,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        criterion=criterion,\n",
        "        device=device,\n",
        "        is_topk=is_topk,\n",
        "        HLNET_LOSS_WEIGHT=HL_NET_LOSS_weight,\n",
        "        RECON_LOSS_WEIGHT=RECON_LOSS_weight,\n",
        "        val_loader=val_loader\n",
        "    )\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    if val_loss is not None:\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    pr_auc, pr_auc_online = test_hl_vae(test_loader, model, device)\n",
        "\n",
        "    if pr_auc > best_pr_auc:\n",
        "        best_pr_auc = pr_auc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{args.max_epoch}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}')\n",
        "    if val_loss is not None:\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'PR-AUC (Offline/Online): {pr_auc:.4f}/{pr_auc_online:.4f}')\n",
        "    print(f'Best PR-AUC: {best_pr_auc:.4f} (Epoch {best_epoch+1})')\n",
        "    print(f'Epoch time: {time.time() - st:.2f}s')\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        # Load the best model state\n",
        "        model.load_state_dict(early_stopping.get_best_model_state())\n",
        "        break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if epoch % 5 == 0 and epoch > 0:\n",
        "        save_dir = './hlnet_saves_audio'\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        torch.save(model.state_dict(), f'{save_dir}/{args.model_name}{epoch}.pth')\n",
        "\n",
        "save_dir = './hlnet_saves_audio/final'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(model.state_dict(), f'{save_dir}/audio_{args.model_name}{epoch}.pth')\n",
        "plot_training_history(train_losses, val_losses, save_path='hlnet_vae_audio_training_history.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BZSK6Q7THHfn",
        "outputId": "beeb25c0-d545-40d0-910e-512245809b9c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating data loaders...\n",
            "Train loader created with 3163 samples\n",
            "Validation loader created with 791 samples\n",
            "Test loader created with 800 samples\n",
            "\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-c78b957fb0b8>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vae_model.load_state_dict(torch.load(vae_dir))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 1/200:\n",
            "Train Loss: 2.3285\n",
            "Validation Loss: 1.6906\n",
            "PR-AUC (Offline/Online): 0.8730/0.7986\n",
            "Best PR-AUC: 0.8730 (Epoch 1)\n",
            "Epoch time: 15.30s\n",
            "\n",
            "Epoch 2/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 2/200:\n",
            "Train Loss: 1.4376\n",
            "Validation Loss: 1.6638\n",
            "PR-AUC (Offline/Online): 0.8920/0.5679\n",
            "Best PR-AUC: 0.8920 (Epoch 2)\n",
            "Epoch time: 10.14s\n",
            "\n",
            "Epoch 3/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 3/200:\n",
            "Train Loss: 1.4102\n",
            "Validation Loss: 1.6500\n",
            "PR-AUC (Offline/Online): 0.9293/0.4782\n",
            "Best PR-AUC: 0.9293 (Epoch 3)\n",
            "Epoch time: 8.34s\n",
            "\n",
            "Epoch 4/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 4/200:\n",
            "Train Loss: 1.3469\n",
            "Validation Loss: 1.5162\n",
            "PR-AUC (Offline/Online): 0.9716/0.4579\n",
            "Best PR-AUC: 0.9716 (Epoch 4)\n",
            "Epoch time: 10.00s\n",
            "\n",
            "Epoch 5/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 5/200:\n",
            "Train Loss: 1.2407\n",
            "Validation Loss: 1.4150\n",
            "PR-AUC (Offline/Online): 0.9876/0.5148\n",
            "Best PR-AUC: 0.9876 (Epoch 5)\n",
            "Epoch time: 9.58s\n",
            "\n",
            "Epoch 6/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 6/200:\n",
            "Train Loss: 1.1546\n",
            "Validation Loss: 1.3599\n",
            "PR-AUC (Offline/Online): 0.9941/0.6208\n",
            "Best PR-AUC: 0.9941 (Epoch 6)\n",
            "Epoch time: 9.23s\n",
            "\n",
            "Epoch 7/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 7/200:\n",
            "Train Loss: 1.1166\n",
            "Validation Loss: 1.2967\n",
            "PR-AUC (Offline/Online): 0.9953/0.7155\n",
            "Best PR-AUC: 0.9953 (Epoch 7)\n",
            "Epoch time: 9.86s\n",
            "\n",
            "Epoch 8/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 8/200:\n",
            "Train Loss: 1.0861\n",
            "Validation Loss: 1.2754\n",
            "PR-AUC (Offline/Online): 0.9970/0.8167\n",
            "Best PR-AUC: 0.9970 (Epoch 8)\n",
            "Epoch time: 8.69s\n",
            "\n",
            "Epoch 9/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 9/200:\n",
            "Train Loss: 1.0647\n",
            "Validation Loss: 1.2388\n",
            "PR-AUC (Offline/Online): 0.9977/0.8846\n",
            "Best PR-AUC: 0.9977 (Epoch 9)\n",
            "Epoch time: 9.87s\n",
            "\n",
            "Epoch 10/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 10/200:\n",
            "Train Loss: 1.0367\n",
            "Validation Loss: 1.1941\n",
            "PR-AUC (Offline/Online): 0.9982/0.9236\n",
            "Best PR-AUC: 0.9982 (Epoch 10)\n",
            "Epoch time: 9.50s\n",
            "\n",
            "Epoch 11/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 11/200:\n",
            "Train Loss: 1.0440\n",
            "Validation Loss: 1.2009\n",
            "PR-AUC (Offline/Online): 0.9983/0.9246\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.33s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 12/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 12/200:\n",
            "Train Loss: 1.0278\n",
            "Validation Loss: 1.1965\n",
            "PR-AUC (Offline/Online): 0.9982/0.9256\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.00s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 13/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 13/200:\n",
            "Train Loss: 1.0264\n",
            "Validation Loss: 1.1965\n",
            "PR-AUC (Offline/Online): 0.9983/0.9278\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.41s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 14/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 14/200:\n",
            "Train Loss: 1.0235\n",
            "Validation Loss: 1.1916\n",
            "PR-AUC (Offline/Online): 0.9983/0.9307\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.26s\n",
            "\n",
            "Epoch 15/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 15/200:\n",
            "Train Loss: 1.0282\n",
            "Validation Loss: 1.1801\n",
            "PR-AUC (Offline/Online): 0.9983/0.9322\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.70s\n",
            "\n",
            "Epoch 16/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 16/200:\n",
            "Train Loss: 1.0323\n",
            "Validation Loss: 1.1840\n",
            "PR-AUC (Offline/Online): 0.9982/0.9342\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.21s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 17/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 17/200:\n",
            "Train Loss: 1.0198\n",
            "Validation Loss: 1.1924\n",
            "PR-AUC (Offline/Online): 0.9980/0.9354\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.12s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 18/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 18/200:\n",
            "Train Loss: 1.0462\n",
            "Validation Loss: 1.1853\n",
            "PR-AUC (Offline/Online): 0.9980/0.9373\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.16s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 19/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 19/200:\n",
            "Train Loss: 1.0119\n",
            "Validation Loss: 1.1885\n",
            "PR-AUC (Offline/Online): 0.9980/0.9396\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.99s\n",
            "EarlyStopping counter: 4 out of 7\n",
            "\n",
            "Epoch 20/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 20/200:\n",
            "Train Loss: 1.0123\n",
            "Validation Loss: 1.1824\n",
            "PR-AUC (Offline/Online): 0.9979/0.9415\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.85s\n",
            "EarlyStopping counter: 5 out of 7\n",
            "\n",
            "Epoch 21/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 21/200:\n",
            "Train Loss: 1.0077\n",
            "Validation Loss: 1.1782\n",
            "PR-AUC (Offline/Online): 0.9979/0.9427\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.26s\n",
            "\n",
            "Epoch 22/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 22/200:\n",
            "Train Loss: 1.0055\n",
            "Validation Loss: 1.1744\n",
            "PR-AUC (Offline/Online): 0.9979/0.9432\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.06s\n",
            "\n",
            "Epoch 23/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 23/200:\n",
            "Train Loss: 1.0344\n",
            "Validation Loss: 1.1692\n",
            "PR-AUC (Offline/Online): 0.9979/0.9461\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.62s\n",
            "\n",
            "Epoch 24/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 24/200:\n",
            "Train Loss: 1.0297\n",
            "Validation Loss: 1.1669\n",
            "PR-AUC (Offline/Online): 0.9979/0.9483\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.03s\n",
            "\n",
            "Epoch 25/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 25/200:\n",
            "Train Loss: 1.0069\n",
            "Validation Loss: 1.1672\n",
            "PR-AUC (Offline/Online): 0.9979/0.9486\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.27s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 26/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 26/200:\n",
            "Train Loss: 1.0095\n",
            "Validation Loss: 1.1686\n",
            "PR-AUC (Offline/Online): 0.9979/0.9501\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.62s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 27/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 27/200:\n",
            "Train Loss: 1.0083\n",
            "Validation Loss: 1.1629\n",
            "PR-AUC (Offline/Online): 0.9979/0.9512\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.55s\n",
            "\n",
            "Epoch 28/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 28/200:\n",
            "Train Loss: 0.9976\n",
            "Validation Loss: 1.1606\n",
            "PR-AUC (Offline/Online): 0.9979/0.9521\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.01s\n",
            "\n",
            "Epoch 29/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 29/200:\n",
            "Train Loss: 1.0262\n",
            "Validation Loss: 1.1580\n",
            "PR-AUC (Offline/Online): 0.9979/0.9527\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.20s\n",
            "\n",
            "Epoch 30/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 30/200:\n",
            "Train Loss: 1.0315\n",
            "Validation Loss: 1.1505\n",
            "PR-AUC (Offline/Online): 0.9979/0.9540\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.11s\n",
            "\n",
            "Epoch 31/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 31/200:\n",
            "Train Loss: 0.9964\n",
            "Validation Loss: 1.1501\n",
            "PR-AUC (Offline/Online): 0.9979/0.9553\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.35s\n",
            "\n",
            "Epoch 32/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 32/200:\n",
            "Train Loss: 0.9902\n",
            "Validation Loss: 1.1499\n",
            "PR-AUC (Offline/Online): 0.9979/0.9556\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.13s\n",
            "\n",
            "Epoch 33/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 33/200:\n",
            "Train Loss: 0.9934\n",
            "Validation Loss: 1.1501\n",
            "PR-AUC (Offline/Online): 0.9979/0.9560\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.75s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 34/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 34/200:\n",
            "Train Loss: 0.9892\n",
            "Validation Loss: 1.1394\n",
            "PR-AUC (Offline/Online): 0.9980/0.9567\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.46s\n",
            "\n",
            "Epoch 35/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 35/200:\n",
            "Train Loss: 1.0103\n",
            "Validation Loss: 1.1475\n",
            "PR-AUC (Offline/Online): 0.9977/0.9569\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.73s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 36/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 36/200:\n",
            "Train Loss: 1.0201\n",
            "Validation Loss: 1.1464\n",
            "PR-AUC (Offline/Online): 0.9979/0.9576\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.67s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 37/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 37/200:\n",
            "Train Loss: 1.0327\n",
            "Validation Loss: 1.1382\n",
            "PR-AUC (Offline/Online): 0.9980/0.9581\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.29s\n",
            "\n",
            "Epoch 38/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 38/200:\n",
            "Train Loss: 0.9991\n",
            "Validation Loss: 1.1401\n",
            "PR-AUC (Offline/Online): 0.9978/0.9585\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.92s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 39/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 39/200:\n",
            "Train Loss: 0.9931\n",
            "Validation Loss: 1.1338\n",
            "PR-AUC (Offline/Online): 0.9979/0.9588\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.60s\n",
            "\n",
            "Epoch 40/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 40/200:\n",
            "Train Loss: 0.9840\n",
            "Validation Loss: 1.1458\n",
            "PR-AUC (Offline/Online): 0.9975/0.9582\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.74s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 41/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 41/200:\n",
            "Train Loss: 0.9873\n",
            "Validation Loss: 1.1263\n",
            "PR-AUC (Offline/Online): 0.9979/0.9598\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.21s\n",
            "\n",
            "Epoch 42/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 42/200:\n",
            "Train Loss: 0.9827\n",
            "Validation Loss: 1.1325\n",
            "PR-AUC (Offline/Online): 0.9977/0.9600\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.45s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 43/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 43/200:\n",
            "Train Loss: 0.9890\n",
            "Validation Loss: 1.1253\n",
            "PR-AUC (Offline/Online): 0.9980/0.9616\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.93s\n",
            "\n",
            "Epoch 44/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 44/200:\n",
            "Train Loss: 1.0037\n",
            "Validation Loss: 1.1319\n",
            "PR-AUC (Offline/Online): 0.9977/0.9618\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.96s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 45/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 45/200:\n",
            "Train Loss: 0.9765\n",
            "Validation Loss: 1.1234\n",
            "PR-AUC (Offline/Online): 0.9977/0.9623\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.51s\n",
            "\n",
            "Epoch 46/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 46/200:\n",
            "Train Loss: 1.0204\n",
            "Validation Loss: 1.1144\n",
            "PR-AUC (Offline/Online): 0.9977/0.9627\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.21s\n",
            "\n",
            "Epoch 47/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 47/200:\n",
            "Train Loss: 1.0120\n",
            "Validation Loss: 1.1198\n",
            "PR-AUC (Offline/Online): 0.9980/0.9630\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.58s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 48/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 48/200:\n",
            "Train Loss: 0.9703\n",
            "Validation Loss: 1.1217\n",
            "PR-AUC (Offline/Online): 0.9980/0.9639\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.45s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 49/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 49/200:\n",
            "Train Loss: 0.9658\n",
            "Validation Loss: 1.1137\n",
            "PR-AUC (Offline/Online): 0.9978/0.9638\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.24s\n",
            "\n",
            "Epoch 50/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 50/200:\n",
            "Train Loss: 0.9716\n",
            "Validation Loss: 1.1097\n",
            "PR-AUC (Offline/Online): 0.9980/0.9646\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.65s\n",
            "\n",
            "Epoch 51/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 51/200:\n",
            "Train Loss: 0.9860\n",
            "Validation Loss: 1.1089\n",
            "PR-AUC (Offline/Online): 0.9980/0.9660\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.84s\n",
            "\n",
            "Epoch 52/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 52/200:\n",
            "Train Loss: 0.9884\n",
            "Validation Loss: 1.1088\n",
            "PR-AUC (Offline/Online): 0.9978/0.9643\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.20s\n",
            "\n",
            "Epoch 53/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 53/200:\n",
            "Train Loss: 0.9981\n",
            "Validation Loss: 1.1085\n",
            "PR-AUC (Offline/Online): 0.9979/0.9667\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.14s\n",
            "\n",
            "Epoch 54/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 54/200:\n",
            "Train Loss: 0.9756\n",
            "Validation Loss: 1.1067\n",
            "PR-AUC (Offline/Online): 0.9975/0.9659\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.95s\n",
            "\n",
            "Epoch 55/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 55/200:\n",
            "Train Loss: 0.9819\n",
            "Validation Loss: 1.1007\n",
            "PR-AUC (Offline/Online): 0.9978/0.9677\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.42s\n",
            "\n",
            "Epoch 56/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 56/200:\n",
            "Train Loss: 0.9799\n",
            "Validation Loss: 1.0972\n",
            "PR-AUC (Offline/Online): 0.9978/0.9678\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.77s\n",
            "\n",
            "Epoch 57/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 57/200:\n",
            "Train Loss: 0.9772\n",
            "Validation Loss: 1.0958\n",
            "PR-AUC (Offline/Online): 0.9979/0.9670\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.21s\n",
            "\n",
            "Epoch 58/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 58/200:\n",
            "Train Loss: 0.9800\n",
            "Validation Loss: 1.1002\n",
            "PR-AUC (Offline/Online): 0.9975/0.9674\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.19s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 59/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 59/200:\n",
            "Train Loss: 0.9653\n",
            "Validation Loss: 1.0929\n",
            "PR-AUC (Offline/Online): 0.9980/0.9690\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.90s\n",
            "\n",
            "Epoch 60/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 60/200:\n",
            "Train Loss: 0.9750\n",
            "Validation Loss: 1.0918\n",
            "PR-AUC (Offline/Online): 0.9980/0.9703\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.79s\n",
            "\n",
            "Epoch 61/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 61/200:\n",
            "Train Loss: 0.9531\n",
            "Validation Loss: 1.0871\n",
            "PR-AUC (Offline/Online): 0.9980/0.9706\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.92s\n",
            "\n",
            "Epoch 62/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 62/200:\n",
            "Train Loss: 0.9739\n",
            "Validation Loss: 1.0842\n",
            "PR-AUC (Offline/Online): 0.9980/0.9711\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.87s\n",
            "\n",
            "Epoch 63/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 63/200:\n",
            "Train Loss: 0.9697\n",
            "Validation Loss: 1.0827\n",
            "PR-AUC (Offline/Online): 0.9980/0.9721\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.34s\n",
            "\n",
            "Epoch 64/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 64/200:\n",
            "Train Loss: 0.9675\n",
            "Validation Loss: 1.0770\n",
            "PR-AUC (Offline/Online): 0.9980/0.9703\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 12.13s\n",
            "\n",
            "Epoch 65/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 65/200:\n",
            "Train Loss: 0.9719\n",
            "Validation Loss: 1.0836\n",
            "PR-AUC (Offline/Online): 0.9980/0.9714\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.93s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 66/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 66/200:\n",
            "Train Loss: 0.9530\n",
            "Validation Loss: 1.0863\n",
            "PR-AUC (Offline/Online): 0.9980/0.9714\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.25s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 67/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 67/200:\n",
            "Train Loss: 1.0007\n",
            "Validation Loss: 1.0843\n",
            "PR-AUC (Offline/Online): 0.9980/0.9716\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.00s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 68/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 68/200:\n",
            "Train Loss: 0.9663\n",
            "Validation Loss: 1.0761\n",
            "PR-AUC (Offline/Online): 0.9979/0.9705\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.95s\n",
            "\n",
            "Epoch 69/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 69/200:\n",
            "Train Loss: 0.9379\n",
            "Validation Loss: 1.0622\n",
            "PR-AUC (Offline/Online): 0.9980/0.9730\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.55s\n",
            "\n",
            "Epoch 70/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 70/200:\n",
            "Train Loss: 0.9704\n",
            "Validation Loss: 1.0700\n",
            "PR-AUC (Offline/Online): 0.9980/0.9735\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.62s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 71/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 71/200:\n",
            "Train Loss: 0.9405\n",
            "Validation Loss: 1.0639\n",
            "PR-AUC (Offline/Online): 0.9980/0.9739\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.24s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 72/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 72/200:\n",
            "Train Loss: 0.9625\n",
            "Validation Loss: 1.0707\n",
            "PR-AUC (Offline/Online): 0.9980/0.9731\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.95s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 73/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 73/200:\n",
            "Train Loss: 0.9309\n",
            "Validation Loss: 1.0621\n",
            "PR-AUC (Offline/Online): 0.9980/0.9741\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.81s\n",
            "\n",
            "Epoch 74/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 74/200:\n",
            "Train Loss: 0.9642\n",
            "Validation Loss: 1.0643\n",
            "PR-AUC (Offline/Online): 0.9980/0.9723\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.62s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 75/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 75/200:\n",
            "Train Loss: 0.9602\n",
            "Validation Loss: 1.0659\n",
            "PR-AUC (Offline/Online): 0.9980/0.9725\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.95s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 76/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 76/200:\n",
            "Train Loss: 0.9373\n",
            "Validation Loss: 1.0575\n",
            "PR-AUC (Offline/Online): 0.9980/0.9736\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.81s\n",
            "\n",
            "Epoch 77/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 77/200:\n",
            "Train Loss: 0.9575\n",
            "Validation Loss: 1.0469\n",
            "PR-AUC (Offline/Online): 0.9980/0.9748\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.35s\n",
            "\n",
            "Epoch 78/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 78/200:\n",
            "Train Loss: 0.9307\n",
            "Validation Loss: 1.0559\n",
            "PR-AUC (Offline/Online): 0.9979/0.9740\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.37s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 79/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 79/200:\n",
            "Train Loss: 0.9588\n",
            "Validation Loss: 1.0550\n",
            "PR-AUC (Offline/Online): 0.9980/0.9740\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.27s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 80/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 80/200:\n",
            "Train Loss: 0.9285\n",
            "Validation Loss: 1.0448\n",
            "PR-AUC (Offline/Online): 0.9979/0.9741\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.07s\n",
            "\n",
            "Epoch 81/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 81/200:\n",
            "Train Loss: 0.9515\n",
            "Validation Loss: 1.0473\n",
            "PR-AUC (Offline/Online): 0.9979/0.9745\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.82s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 82/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 82/200:\n",
            "Train Loss: 0.9488\n",
            "Validation Loss: 1.0499\n",
            "PR-AUC (Offline/Online): 0.9980/0.9746\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.50s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 83/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 83/200:\n",
            "Train Loss: 0.9238\n",
            "Validation Loss: 1.0445\n",
            "PR-AUC (Offline/Online): 0.9980/0.9759\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.90s\n",
            "\n",
            "Epoch 84/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 84/200:\n",
            "Train Loss: 0.9480\n",
            "Validation Loss: 1.0458\n",
            "PR-AUC (Offline/Online): 0.9980/0.9759\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.72s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 85/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 85/200:\n",
            "Train Loss: 0.9246\n",
            "Validation Loss: 1.0375\n",
            "PR-AUC (Offline/Online): 0.9979/0.9763\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.71s\n",
            "\n",
            "Epoch 86/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 86/200:\n",
            "Train Loss: 0.9425\n",
            "Validation Loss: 1.0401\n",
            "PR-AUC (Offline/Online): 0.9979/0.9763\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 11.98s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 87/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 87/200:\n",
            "Train Loss: 0.9188\n",
            "Validation Loss: 1.0433\n",
            "PR-AUC (Offline/Online): 0.9979/0.9766\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.36s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 88/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 88/200:\n",
            "Train Loss: 0.9405\n",
            "Validation Loss: 1.0326\n",
            "PR-AUC (Offline/Online): 0.9979/0.9766\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.13s\n",
            "\n",
            "Epoch 89/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 89/200:\n",
            "Train Loss: 0.9484\n",
            "Validation Loss: 1.0297\n",
            "PR-AUC (Offline/Online): 0.9979/0.9768\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.72s\n",
            "\n",
            "Epoch 90/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 90/200:\n",
            "Train Loss: 0.9413\n",
            "Validation Loss: 1.0399\n",
            "PR-AUC (Offline/Online): 0.9980/0.9760\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.22s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 91/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 91/200:\n",
            "Train Loss: 0.9418\n",
            "Validation Loss: 1.0227\n",
            "PR-AUC (Offline/Online): 0.9979/0.9761\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.87s\n",
            "\n",
            "Epoch 92/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 92/200:\n",
            "Train Loss: 0.9317\n",
            "Validation Loss: 1.0237\n",
            "PR-AUC (Offline/Online): 0.9980/0.9762\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.16s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 93/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 93/200:\n",
            "Train Loss: 0.9112\n",
            "Validation Loss: 1.0304\n",
            "PR-AUC (Offline/Online): 0.9980/0.9762\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.02s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 94/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 94/200:\n",
            "Train Loss: 0.9373\n",
            "Validation Loss: 1.0157\n",
            "PR-AUC (Offline/Online): 0.9979/0.9763\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.21s\n",
            "\n",
            "Epoch 95/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 95/200:\n",
            "Train Loss: 0.9382\n",
            "Validation Loss: 1.0222\n",
            "PR-AUC (Offline/Online): 0.9979/0.9764\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.97s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 96/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 96/200:\n",
            "Train Loss: 0.9017\n",
            "Validation Loss: 1.0141\n",
            "PR-AUC (Offline/Online): 0.9979/0.9765\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.20s\n",
            "\n",
            "Epoch 97/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 97/200:\n",
            "Train Loss: 0.9268\n",
            "Validation Loss: 1.0145\n",
            "PR-AUC (Offline/Online): 0.9981/0.9784\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.74s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 98/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 98/200:\n",
            "Train Loss: 0.9001\n",
            "Validation Loss: 1.0207\n",
            "PR-AUC (Offline/Online): 0.9980/0.9785\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.78s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 99/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 99/200:\n",
            "Train Loss: 0.9024\n",
            "Validation Loss: 1.0152\n",
            "PR-AUC (Offline/Online): 0.9981/0.9787\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.94s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 100/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 100/200:\n",
            "Train Loss: 0.9014\n",
            "Validation Loss: 1.0076\n",
            "PR-AUC (Offline/Online): 0.9981/0.9789\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.60s\n",
            "\n",
            "Epoch 101/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 101/200:\n",
            "Train Loss: 0.9383\n",
            "Validation Loss: 1.0051\n",
            "PR-AUC (Offline/Online): 0.9981/0.9790\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.10s\n",
            "\n",
            "Epoch 102/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 102/200:\n",
            "Train Loss: 0.9075\n",
            "Validation Loss: 1.0083\n",
            "PR-AUC (Offline/Online): 0.9981/0.9782\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.68s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 103/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 103/200:\n",
            "Train Loss: 0.9033\n",
            "Validation Loss: 1.0030\n",
            "PR-AUC (Offline/Online): 0.9981/0.9783\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.71s\n",
            "\n",
            "Epoch 104/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 104/200:\n",
            "Train Loss: 0.8947\n",
            "Validation Loss: 0.9979\n",
            "PR-AUC (Offline/Online): 0.9981/0.9791\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.36s\n",
            "\n",
            "Epoch 105/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 105/200:\n",
            "Train Loss: 0.8924\n",
            "Validation Loss: 0.9887\n",
            "PR-AUC (Offline/Online): 0.9981/0.9805\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.79s\n",
            "\n",
            "Epoch 106/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 106/200:\n",
            "Train Loss: 0.9216\n",
            "Validation Loss: 1.0084\n",
            "PR-AUC (Offline/Online): 0.9981/0.9801\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.15s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 107/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 107/200:\n",
            "Train Loss: 0.9185\n",
            "Validation Loss: 0.9966\n",
            "PR-AUC (Offline/Online): 0.9981/0.9796\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.93s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 108/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 108/200:\n",
            "Train Loss: 0.9044\n",
            "Validation Loss: 1.0028\n",
            "PR-AUC (Offline/Online): 0.9981/0.9788\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.67s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 109/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 109/200:\n",
            "Train Loss: 0.9221\n",
            "Validation Loss: 0.9957\n",
            "PR-AUC (Offline/Online): 0.9981/0.9809\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.35s\n",
            "EarlyStopping counter: 4 out of 7\n",
            "\n",
            "Epoch 110/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 110/200:\n",
            "Train Loss: 0.8881\n",
            "Validation Loss: 0.9927\n",
            "PR-AUC (Offline/Online): 0.9981/0.9809\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.42s\n",
            "EarlyStopping counter: 5 out of 7\n",
            "\n",
            "Epoch 111/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 111/200:\n",
            "Train Loss: 0.8880\n",
            "Validation Loss: 0.9882\n",
            "PR-AUC (Offline/Online): 0.9981/0.9809\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.58s\n",
            "\n",
            "Epoch 112/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 112/200:\n",
            "Train Loss: 0.9326\n",
            "Validation Loss: 0.9894\n",
            "PR-AUC (Offline/Online): 0.9981/0.9803\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.74s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 113/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 113/200:\n",
            "Train Loss: 0.9292\n",
            "Validation Loss: 0.9774\n",
            "PR-AUC (Offline/Online): 0.9979/0.9815\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.37s\n",
            "\n",
            "Epoch 114/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 114/200:\n",
            "Train Loss: 0.9084\n",
            "Validation Loss: 0.9788\n",
            "PR-AUC (Offline/Online): 0.9980/0.9815\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.41s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 115/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 115/200:\n",
            "Train Loss: 0.8897\n",
            "Validation Loss: 0.9732\n",
            "PR-AUC (Offline/Online): 0.9979/0.9815\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.11s\n",
            "\n",
            "Epoch 116/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 116/200:\n",
            "Train Loss: 0.9073\n",
            "Validation Loss: 0.9797\n",
            "PR-AUC (Offline/Online): 0.9979/0.9815\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.07s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 117/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 117/200:\n",
            "Train Loss: 0.9245\n",
            "Validation Loss: 0.9758\n",
            "PR-AUC (Offline/Online): 0.9979/0.9823\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.49s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 118/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 118/200:\n",
            "Train Loss: 0.8801\n",
            "Validation Loss: 0.9717\n",
            "PR-AUC (Offline/Online): 0.9981/0.9823\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.73s\n",
            "\n",
            "Epoch 119/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 119/200:\n",
            "Train Loss: 0.9078\n",
            "Validation Loss: 0.9715\n",
            "PR-AUC (Offline/Online): 0.9979/0.9823\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.46s\n",
            "\n",
            "Epoch 120/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 120/200:\n",
            "Train Loss: 0.8973\n",
            "Validation Loss: 0.9701\n",
            "PR-AUC (Offline/Online): 0.9981/0.9823\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.96s\n",
            "\n",
            "Epoch 121/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 121/200:\n",
            "Train Loss: 0.8781\n",
            "Validation Loss: 0.9769\n",
            "PR-AUC (Offline/Online): 0.9980/0.9823\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.81s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 122/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 122/200:\n",
            "Train Loss: 0.8693\n",
            "Validation Loss: 0.9628\n",
            "PR-AUC (Offline/Online): 0.9979/0.9824\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.29s\n",
            "\n",
            "Epoch 123/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 123/200:\n",
            "Train Loss: 0.8663\n",
            "Validation Loss: 0.9615\n",
            "PR-AUC (Offline/Online): 0.9979/0.9825\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.92s\n",
            "\n",
            "Epoch 124/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 124/200:\n",
            "Train Loss: 0.8751\n",
            "Validation Loss: 0.9651\n",
            "PR-AUC (Offline/Online): 0.9979/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.80s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 125/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 125/200:\n",
            "Train Loss: 0.9005\n",
            "Validation Loss: 0.9610\n",
            "PR-AUC (Offline/Online): 0.9982/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.48s\n",
            "\n",
            "Epoch 126/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 126/200:\n",
            "Train Loss: 0.8621\n",
            "Validation Loss: 0.9541\n",
            "PR-AUC (Offline/Online): 0.9982/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.09s\n",
            "\n",
            "Epoch 127/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 127/200:\n",
            "Train Loss: 0.8905\n",
            "Validation Loss: 0.9574\n",
            "PR-AUC (Offline/Online): 0.9983/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.92s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 128/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 128/200:\n",
            "Train Loss: 0.8955\n",
            "Validation Loss: 0.9592\n",
            "PR-AUC (Offline/Online): 0.9982/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.53s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 129/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 129/200:\n",
            "Train Loss: 0.9161\n",
            "Validation Loss: 0.9511\n",
            "PR-AUC (Offline/Online): 0.9982/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.94s\n",
            "\n",
            "Epoch 130/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 130/200:\n",
            "Train Loss: 0.8655\n",
            "Validation Loss: 0.9533\n",
            "PR-AUC (Offline/Online): 0.9983/0.9830\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.31s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 131/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 131/200:\n",
            "Train Loss: 0.8922\n",
            "Validation Loss: 0.9470\n",
            "PR-AUC (Offline/Online): 0.9981/0.9835\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.97s\n",
            "\n",
            "Epoch 132/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 132/200:\n",
            "Train Loss: 0.9064\n",
            "Validation Loss: 0.9406\n",
            "PR-AUC (Offline/Online): 0.9982/0.9835\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.60s\n",
            "\n",
            "Epoch 133/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 133/200:\n",
            "Train Loss: 0.8812\n",
            "Validation Loss: 0.9460\n",
            "PR-AUC (Offline/Online): 0.9982/0.9836\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.30s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 134/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 134/200:\n",
            "Train Loss: 0.8588\n",
            "Validation Loss: 0.9418\n",
            "PR-AUC (Offline/Online): 0.9983/0.9841\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.18s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 135/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 135/200:\n",
            "Train Loss: 0.8536\n",
            "Validation Loss: 0.9427\n",
            "PR-AUC (Offline/Online): 0.9983/0.9841\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.42s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 136/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 136/200:\n",
            "Train Loss: 0.8827\n",
            "Validation Loss: 0.9394\n",
            "PR-AUC (Offline/Online): 0.9983/0.9841\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.49s\n",
            "\n",
            "Epoch 137/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 137/200:\n",
            "Train Loss: 0.8535\n",
            "Validation Loss: 0.9435\n",
            "PR-AUC (Offline/Online): 0.9983/0.9841\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.99s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 138/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 138/200:\n",
            "Train Loss: 0.8731\n",
            "Validation Loss: 0.9355\n",
            "PR-AUC (Offline/Online): 0.9983/0.9841\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.19s\n",
            "\n",
            "Epoch 139/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 139/200:\n",
            "Train Loss: 0.8802\n",
            "Validation Loss: 0.9364\n",
            "PR-AUC (Offline/Online): 0.9983/0.9841\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.86s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 140/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 140/200:\n",
            "Train Loss: 0.8478\n",
            "Validation Loss: 0.9325\n",
            "PR-AUC (Offline/Online): 0.9982/0.9851\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.63s\n",
            "\n",
            "Epoch 141/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 141/200:\n",
            "Train Loss: 0.8694\n",
            "Validation Loss: 0.9387\n",
            "PR-AUC (Offline/Online): 0.9982/0.9851\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.67s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 142/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 142/200:\n",
            "Train Loss: 0.8647\n",
            "Validation Loss: 0.9262\n",
            "PR-AUC (Offline/Online): 0.9982/0.9855\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.73s\n",
            "\n",
            "Epoch 143/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 143/200:\n",
            "Train Loss: 0.8518\n",
            "Validation Loss: 0.9265\n",
            "PR-AUC (Offline/Online): 0.9982/0.9855\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.17s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 144/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 144/200:\n",
            "Train Loss: 0.8483\n",
            "Validation Loss: 0.9269\n",
            "PR-AUC (Offline/Online): 0.9982/0.9855\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.75s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 145/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 145/200:\n",
            "Train Loss: 0.8462\n",
            "Validation Loss: 0.9191\n",
            "PR-AUC (Offline/Online): 0.9982/0.9855\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.31s\n",
            "\n",
            "Epoch 146/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 146/200:\n",
            "Train Loss: 0.8708\n",
            "Validation Loss: 0.9236\n",
            "PR-AUC (Offline/Online): 0.9983/0.9855\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.09s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 147/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 147/200:\n",
            "Train Loss: 0.8666\n",
            "Validation Loss: 0.9238\n",
            "PR-AUC (Offline/Online): 0.9981/0.9863\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.74s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 148/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 148/200:\n",
            "Train Loss: 0.8391\n",
            "Validation Loss: 0.9143\n",
            "PR-AUC (Offline/Online): 0.9982/0.9871\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.40s\n",
            "\n",
            "Epoch 149/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 149/200:\n",
            "Train Loss: 0.8399\n",
            "Validation Loss: 0.9137\n",
            "PR-AUC (Offline/Online): 0.9982/0.9874\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.28s\n",
            "\n",
            "Epoch 150/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 150/200:\n",
            "Train Loss: 0.8411\n",
            "Validation Loss: 0.9098\n",
            "PR-AUC (Offline/Online): 0.9981/0.9874\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.81s\n",
            "\n",
            "Epoch 151/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 151/200:\n",
            "Train Loss: 0.8366\n",
            "Validation Loss: 0.9166\n",
            "PR-AUC (Offline/Online): 0.9981/0.9878\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.59s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 152/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 152/200:\n",
            "Train Loss: 0.8652\n",
            "Validation Loss: 0.9160\n",
            "PR-AUC (Offline/Online): 0.9983/0.9878\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 11.56s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 153/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 153/200:\n",
            "Train Loss: 0.8555\n",
            "Validation Loss: 0.9100\n",
            "PR-AUC (Offline/Online): 0.9981/0.9878\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.80s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 154/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 154/200:\n",
            "Train Loss: 0.8317\n",
            "Validation Loss: 0.9117\n",
            "PR-AUC (Offline/Online): 0.9981/0.9878\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.15s\n",
            "EarlyStopping counter: 4 out of 7\n",
            "\n",
            "Epoch 155/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 155/200:\n",
            "Train Loss: 0.8282\n",
            "Validation Loss: 0.9044\n",
            "PR-AUC (Offline/Online): 0.9983/0.9881\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.14s\n",
            "\n",
            "Epoch 156/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 156/200:\n",
            "Train Loss: 0.8358\n",
            "Validation Loss: 0.9047\n",
            "PR-AUC (Offline/Online): 0.9982/0.9886\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.11s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 157/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 157/200:\n",
            "Train Loss: 0.8541\n",
            "Validation Loss: 0.9002\n",
            "PR-AUC (Offline/Online): 0.9983/0.9886\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.04s\n",
            "\n",
            "Epoch 158/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 158/200:\n",
            "Train Loss: 0.8528\n",
            "Validation Loss: 0.9012\n",
            "PR-AUC (Offline/Online): 0.9983/0.9886\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.98s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 159/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 159/200:\n",
            "Train Loss: 0.8330\n",
            "Validation Loss: 0.9030\n",
            "PR-AUC (Offline/Online): 0.9983/0.9889\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.32s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 160/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 160/200:\n",
            "Train Loss: 0.8350\n",
            "Validation Loss: 0.9012\n",
            "PR-AUC (Offline/Online): 0.9982/0.9898\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.85s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 161/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 161/200:\n",
            "Train Loss: 0.8251\n",
            "Validation Loss: 0.8969\n",
            "PR-AUC (Offline/Online): 0.9982/0.9895\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.71s\n",
            "\n",
            "Epoch 162/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 162/200:\n",
            "Train Loss: 0.8448\n",
            "Validation Loss: 0.8937\n",
            "PR-AUC (Offline/Online): 0.9982/0.9898\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.35s\n",
            "\n",
            "Epoch 163/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 163/200:\n",
            "Train Loss: 0.8721\n",
            "Validation Loss: 0.8967\n",
            "PR-AUC (Offline/Online): 0.9983/0.9895\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.89s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 164/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 164/200:\n",
            "Train Loss: 0.8204\n",
            "Validation Loss: 0.8910\n",
            "PR-AUC (Offline/Online): 0.9982/0.9898\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.58s\n",
            "\n",
            "Epoch 165/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 165/200:\n",
            "Train Loss: 0.8280\n",
            "Validation Loss: 0.8978\n",
            "PR-AUC (Offline/Online): 0.9983/0.9898\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.13s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 166/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 166/200:\n",
            "Train Loss: 0.8177\n",
            "Validation Loss: 0.8908\n",
            "PR-AUC (Offline/Online): 0.9982/0.9898\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.82s\n",
            "\n",
            "Epoch 167/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 167/200:\n",
            "Train Loss: 0.8232\n",
            "Validation Loss: 0.8789\n",
            "PR-AUC (Offline/Online): 0.9982/0.9898\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.23s\n",
            "\n",
            "Epoch 168/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 168/200:\n",
            "Train Loss: 0.8246\n",
            "Validation Loss: 0.8860\n",
            "PR-AUC (Offline/Online): 0.9983/0.9900\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.89s\n",
            "EarlyStopping counter: 1 out of 7\n",
            "\n",
            "Epoch 169/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 169/200:\n",
            "Train Loss: 0.8313\n",
            "Validation Loss: 0.8862\n",
            "PR-AUC (Offline/Online): 0.9983/0.9904\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.15s\n",
            "EarlyStopping counter: 2 out of 7\n",
            "\n",
            "Epoch 170/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 170/200:\n",
            "Train Loss: 0.8099\n",
            "Validation Loss: 0.8813\n",
            "PR-AUC (Offline/Online): 0.9983/0.9904\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.18s\n",
            "EarlyStopping counter: 3 out of 7\n",
            "\n",
            "Epoch 171/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 171/200:\n",
            "Train Loss: 0.8420\n",
            "Validation Loss: 0.8916\n",
            "PR-AUC (Offline/Online): 0.9983/0.9904\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 9.61s\n",
            "EarlyStopping counter: 4 out of 7\n",
            "\n",
            "Epoch 172/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 172/200:\n",
            "Train Loss: 0.8080\n",
            "Validation Loss: 0.8851\n",
            "PR-AUC (Offline/Online): 0.9983/0.9904\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 8.55s\n",
            "EarlyStopping counter: 5 out of 7\n",
            "\n",
            "Epoch 173/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 173/200:\n",
            "Train Loss: 0.8167\n",
            "Validation Loss: 0.8836\n",
            "PR-AUC (Offline/Online): 0.9983/0.9904\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.01s\n",
            "EarlyStopping counter: 6 out of 7\n",
            "\n",
            "Epoch 174/200\n",
            "Starting test...\n",
            "Input shape: torch.Size([5, 200, 128])\n",
            "Label shape: torch.Size([5])\n",
            "Logits shape: torch.Size([5, 200, 1])\n",
            "Sig shape before mean: torch.Size([5, 200])\n",
            "Final shapes - GT: (160,), Pred: (160,), Pred2: (160,)\n",
            "Epoch 174/200:\n",
            "Train Loss: 0.8092\n",
            "Validation Loss: 0.8802\n",
            "PR-AUC (Offline/Online): 0.9983/0.9904\n",
            "Best PR-AUC: 0.9983 (Epoch 11)\n",
            "Epoch time: 10.04s\n",
            "EarlyStopping counter: 7 out of 7\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "i9AXr6nozXBO",
        "_cnDUWwO4nUY",
        "bT6hTfCt9ADz",
        "xR_fo5bc9LVf",
        "MArlBOBwT695",
        "7GJ5HGbQ3GE-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}