\documentclass[twocolumn]{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{outlines}

\renewcommand{\labelitemiii}{\textbullet}
\renewcommand{\labelitemiv}{\textendash}

\newcommand{\todo}[1]{\textcolor{red}{#1}}

\title{CS482/682 Final Project Report Group \todo{XX}\\
	\large \todo{your project title here}}

\author{Noah Drakes - ndrakes1}

\date{}

\begin{document}
	
	\maketitle
	
	% do not write an abstract
	\section{Problem Statement}
	% \paragraph{}
	
	The goal of this study is to replicate and fine-tune a currently existing anomaly detection modal in a semi-supervised fashion that utilizes multimodality, 
	video and audio inputs, in order to predict the presence of violent/anomalous events. Examples of anomalous 
	events would be a car crash happening on a busy streat or a fight breaking out in a subway. With the rise of advanced
	surveillance systems, there has been a push toward incorporating ML algorithims in the video security domain. 
	By utiling robust anomaly detection algorithims in computer vision, security teams can quickly and autonomously identify 
	suspicous activity in crowded areas and can help prevent anomalous events from escalating.

	% \paragraph{Related Work} \todo{e.g. previous supervised approaches, other unsupervised methods etc}
	
	\section{Summary of Dataset}
	There are two datasets that are being considered for this project. The first being \textbf{XD-Violence} which
	comprises of 4754 untrimmed videos obtained form YouTube videos that are divided into with corresponding audio signals and weak labels (violent/normal).
	 Another dataset being considered is the \textbf{UCF-Crime} comprising of 1900 untrimmed videos of 13 realistic anomalous events, such as burglary, robbery, fighting, and so. 

	\section{Related Papers}
	The first reference, "Learning Multimodal Violence Detection under Weak Supervision", uses the XD-Violence dataset to detect Violence
	by fusing video and audio modalities and using HL-Net architecture to capture short term and long term temporal information [1]. The source code for the model in this paper is open source 
	so I think we will start with their model architecture, use a downsampled subset of the xd-violence 
	dataset for training, and fine-tune the hyperparameters of their model in a semi-supervised approach.

	There also other papers that try to solve anomaly detection in different ways, such as using a 
	Variational Autoencoder to predict future samples of video, and using the reconstruction error to 
	determine if an anomalous event has occured [2] This Autoencoder reconstruction loss
	method seems like a popular way of getting a per scene violence detection 
	scores. 
	
	\section{Outline}

	\begin{outline}
		\1 Setup
		   \2 Code Setup
				\3 Organize source code referenced in the paper [1] into python notebook style
				\3 Verify we can train and run inference
			
		  \2 Dataset
				\3 Download XD-Violence Dataset and upload it to Google Drive (or server where we 
				perform training)
				\3 Split Dataset into Images for Pseudo-Labels (for Semi Supervision), Training, Validation, Testing. 
				\3 Downsample Videos (x2 x4) depending on length of training time.
		\1 Training
			\2 Semi-Supervision
				\3 Train on subset of training data. 
				\3 Create PseudoLabels and Retrain
				\3 Modify Loss function to consider unsupervised and supervised 
				classification that will need to be hypertuned:

				\[Loss_T  = \alpha * Loss_S + \beta * Loss_{US}\]
				\3 BCE for classification

		\1 Evaluation: 
		\2 Hyperparameter Tuning:
		 Adjust Learning Rate, optimizers, batch sizes, dropout, to increase
		model accuracy over time. 
		\2 Compress Model by reducing layers and overall paramater and observe 
		if accuracy can be preserved.
		\3 Evaluate if similar model accuracy can be achieved with more initial 
		pooling layers to reduce video dimensions.
				
	 \end{outline}
	
	
	\begin{thebibliography}{9}
		\bibitem{paper}
		Shaoyuan Xu, Qi Jin, Yueming Liu, Kai Wang, and Tianqiang Ruan. "Not Only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision." *Proceedings of the European Conference on Computer Vision (ECCV)*, 2020.

		\bibitem{paper}
		S. Xu, Y. Liu, S. Wu, and T. Ruan. "A New Comprehensive Benchmark for Semi-supervised Video Anomaly Detection and Anticipation." *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2021.


		\end{thebibliography}

\end{document}